{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Logistic Regression\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous notebooks, we have seen how to perform linear regression on input data to predict a continuous value. In some cases, however, we wish to predict a categorical value, such as _True/False_ or _Yes/No_. Traditional regression methods are not optimal for these problems, since this requires the prediction of a discrete and not continuous value. In this notebook we introduce a technique that simulates linear regression, but with an additional function employed that maps the continuous value predicted by linear regression methods into a **probability**, or specifically the range $[0, 1]$. In this manner, we can apply a threshold to this probability to predict a binary response.\n",
    "\n",
    "While several functions might be suitable for this transformation, the most popular\n",
    "function is the [_logit_ function][wlf]. Note that some older analyses might reference the [_probit_ function][wpf]. Performing regression by using the logit function is known as [logistic regression][wlr] (the inverse of the logit function is known as the [_logistic_ function][wlcf]). The name might seem confusing since technically this algorithm is used to perform classification, but since logistic regression borrows heavily in its approach from linear regression, the descriptive name was maintained. A major benefit of logistic regression is the creation of a parametric model that can be explored to understand why predictions are made, in the same manner as a linear regression model.\n",
    "\n",
    "In this notebook, we introduce the logit function and how it can be used to construct a binary model. Next, we introduce logistic regression, and specifically show how logistic regression can be performed by using estimators from the scikit-learn library. We also introduce several popular performance metrics and show how they can be calculated for binary classification tasks.\n",
    "\n",
    "-----\n",
    "[wlr]: https://en.wikipedia.org/wiki/Logistic_regression\n",
    "[wlf]: https://en.wikipedia.org/wiki/Logit\n",
    "[wpf]: https://en.wikipedia.org/wiki/Probit\n",
    "[wlcf]: https://en.wikipedia.org/wiki/Logistic_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Formalism](#Formalism)\n",
    "\n",
    "- [Logit Function](#Logit-Function)\n",
    "- [Gradient Descent](#Gradient-Descent)\n",
    "- [Logistic Modelling](#Logistic-Modelling)\n",
    "\n",
    "[Logistic Regression: Adult Data](#LogisticRegression:-Adult-Data)\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [LogisticRegression Model](#LogisticRegression-Model)\n",
    "\n",
    "[Classification Performance Metrics](#Classification-Performance-Metrics)\n",
    "\n",
    "-----\n",
    "\n",
    "Before proceeding with the _Formalism_ section of this Notebook, we first have our standard notebook setup code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We do this to ignore several specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Formalism\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a binary classification process, we have two possible outcomes, which for the sake of generality, we can label as _Success_ or _Failure_. Denoting the probability of these two outcomes as $P(S)$ and $P(F)$ respectively, we can write the probability of success as $P(S) = p$, and the probability of failure as $P(F) = 1 - p$. Thus, the odds of a successful outcome, which is the ratio of the probability of success to the probability of failure, is given by the following expression:\n",
    "\n",
    "$\\textrm{Odds}(S) = \\frac{p}{1 - p}$\n",
    "\n",
    "We can extend the framework of _linear regression_ to the task of binary classification by employing a mapping between the continuous value predicted by a linear regressor and the probability of an event occurring, which is bounded by the range $[0, 1]$. To do this, we need a function that maps the real numbers into this range, which enables a regression onto a set of discrete values (0 or 1) that provides us the binary classification. One popular choice for this function is the _logit_ function, while another choice is the _probit_ function. The use of these functions for a classification task leads to _logistic regression_ or _probit regression_. While we focus in this notebook on the application of logistic regression for the binary classification task, this approach can be generalized to classify into more than two categories, this more advanced technique is known as [multinomial logistic regression][mlr].\n",
    "\n",
    "-----\n",
    "\n",
    "[mlr]: https://en.wikipedia.org/wiki/Multinomial_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Logit Function\n",
    "\n",
    "$\\DeclareMathOperator\\erf{erf}$\n",
    "\n",
    "The [_logit_ function][wl] is defined as the logarithm of the odds (i.e, $p/(1 - p)$), which is also known as the _log-odds_. Thus, the _logit_ function can be written for a probability of success $p$:\n",
    "\n",
    "$\\textrm{logit}(p) = \\log\\left(\\frac{p}{1 - p}\\right)$ where $0 \\leq p \\leq 1$. \n",
    "\n",
    "We can invert this relationship to obtain the [_logistic_ function][wlf], which for a parameter $\\alpha$ is defined by the following expression:\n",
    "\n",
    "$\\textrm{logit}^{-1}(\\alpha) = \\textrm{logistic}(\\alpha) = \\frac{1}{1 + \\exp{(-\\alpha})}$\n",
    "\n",
    "The logit function (and the probit function) is an _S_ shaped curve that converts real numbers into a probability. Both the logit and probit functions are related to the *sigmoid* function, but are centered at the origin (0, 0). In the following Code cell, we plot the $\\textrm{logistic}$ function, or the inverse of the logit function, demonstrating how the real numbers can be mapped into the range $[0, 1]$.\n",
    "\n",
    "**Note:** You are not required to understand the code in the next code cell. Just pay attention to the plot and visualize how real numbers are mapped into [0,1] range.\n",
    "\n",
    "-----\n",
    "[wl]: https://en.wikipedia.org/wiki/Logit\n",
    "[wp]: https://en.wikipedia.org/wiki/Probit\n",
    "[wlf]: https://en.wikipedia.org/wiki/Logistic_function\n",
    "[wef]: https://en.wikipedia.org/wiki/Error_function\n",
    "[mlr]: https://en.wikipedia.org/wiki/Multinomial_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Compute and plot logistic function\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = 1. / (1 + np.exp(-x))\n",
    "ax.plot(x, y, alpha=0.75)\n",
    "\n",
    "# Draw probability barrier\n",
    "ax.hlines(0.5, -10, 10, linestyles='--')\n",
    "\n",
    "# Decorate plot\n",
    "ax.set_xlabel(r'$\\alpha$', fontsize=16)\n",
    "ax.set_ylabel(r'$p$', fontsize=16)\n",
    "ax.set_title('Logistic Function', fontsize=18)\n",
    "sns.despine(offset = 2, trim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Logistic Modelling\n",
    "\n",
    "Before introducing logistic regression, we first show how the logistic function can be used to model binary response data. For this purpose, we will use data from NASA on the relationship between the outside temperature when the space shuttle was launched, and the occurrence of a thermal failure of an O-ring on a booster rocket. We will use this data to create a predictive model between temperature and thermal failure; note that it is believed that the [failure of an O-ring][wsrb] on a solid rocket booster led to the Challenger disaster.\n",
    "\n",
    "We will bypass the logistic regression process and instead explain the concept with two images. The first image is the O-ring test result conducted by NASA. The test recorded the number of O-ring failures under different temperature. The [actual data][ord] we use is hosted at the University of California at Irvine (UCI) machine learning data repository.\n",
    "\n",
    "<img src=\"images/oring.png\" width=\"600\">\n",
    "\n",
    "We can apply logistic regression on this data. The independent variable is temperature. The dependent variable will be whether there's at least one failure, 1 if yes, 0 if no.\n",
    "\n",
    "The cost (or loss) function for logistic regression is the sum of the squared errors between the actual classes and the predicted classes\n",
    "\n",
    "After we apply logistic function and minimize the cost function, we will get a sigmoid curve which is also our predictive model like this:\n",
    "\n",
    "<img src=\"images/sigmoid.png\" width=\"600\">\n",
    "\n",
    "\n",
    "-----\n",
    "[wsrb]: https://en.wikipedia.org/wiki/Space_Shuttle_Solid_Rocket_Booster#Challenger_disaster\n",
    "[ord]: https://archive.ics.uci.edu/ml/machine-learning-databases/space-shuttle/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given this predictive model, we can predict for new, unseen data. In this case, we can predict the probability of thermal failure for a given temperature. We can see that the probability of at least one O-ring failure is about 50% when temperature is 65 degree Fahrenheit. The temperature at launch during the Challenger disaster was 31 degrees Fahrenheit!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## LogisticRegression: Adult Data\n",
    "\n",
    "-----\n",
    "\n",
    "We now will use the `LogisticRegression` estimator in the scikit-learn library to construct a logistic regression model. This estimator accepts a number of hyperparameters, of which the most important for our purposes include:\n",
    "\n",
    "- `C`: inverse of regularization strength, larger `C` reduces overfitting risk.\n",
    "- `class_weight`: weights to be applied to classes when performing regression, default is uniform\n",
    "- `fit_intercept`: specifies if a constant term should be included in the regression, the default is `True`\n",
    "- `random_state`: the seed used to initialize the random number generator, a constant value ensures reproducibility.\n",
    "\n",
    "Run `help(LogisticRegression)` to view more details about the model and the hyper parameters.\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=1E6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "We now turn to a rather complex data set with which to perform logistic regression. The data we will explore next is the adult income prediction data. These data were extracted by Barry Becker from the 1994 Census database and consist of the following features: age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, and salary. Of these, only five are continuous:  fnlwgt, education-num, capital-gain, capital-loss, and hours-per-week, the others are discrete. The last column, salary, is discrete and contains one of two strings to indicate if the salary was below or above $50,000. This is the column we will use to make our label.\n",
    "\n",
    "The data we use is a subset of original data which can be found in the [UCI Machine Learning Repository][uciad].\n",
    "\n",
    "We first use the pandas `read_csv` function to read the data file. Once the DataFrame is created, we randomly sample five rows to verify that the data has been successfully read.\n",
    "\n",
    "Next, we display basic information and descriptive statistics of the dataframe to get more understanding of our data.\n",
    "\n",
    "Next, we encode out target column `Salary` to create a numeric label. We use `value_counts()` to check class balance of the label.\n",
    "\n",
    "Finally, we use patsy module to create dependent and independent variables from the dataframe.\n",
    "\n",
    "-----\n",
    "[uciad]: https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>FNLWGT</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1449</td>\n",
       "      <td>54</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>105010</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>29762</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5013</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>17</td>\n",
       "      <td>?</td>\n",
       "      <td>172145</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>181091</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>57</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>195835</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age          Workclass  FNLWGT      Education  EducationLevel  \\\n",
       "1449   54   Self-emp-not-inc  105010      Bachelors              13   \n",
       "217    41   Self-emp-not-inc   29762   Some-college              10   \n",
       "760    17                  ?  172145           10th               6   \n",
       "306    34            Private  181091        HS-grad               9   \n",
       "3185   57       Self-emp-inc  195835        HS-grad               9   \n",
       "\n",
       "            MaritalStatus        Occupation Relationship    Race      Sex  \\\n",
       "1449   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "217    Married-civ-spouse   Farming-fishing      Husband   White     Male   \n",
       "760         Never-married                 ?    Own-child   Black   Female   \n",
       "306    Married-civ-spouse      Craft-repair      Husband   White     Male   \n",
       "3185   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "\n",
       "      CapitalGain  CapitalLoss  HoursPerWeek   NativeCountry  Salary  \n",
       "1449            0            0            40   United-States    >50K  \n",
       "217          5013            0            70   United-States   <=50K  \n",
       "760             0            0            40   United-States   <=50K  \n",
       "306          7688            0            40   United-States    >50K  \n",
       "3185            0            0            40   United-States   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV data\n",
    "adult_data = pd.read_csv('data/adult_income.csv')\n",
    "\n",
    "# Display random sample\n",
    "adult_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "The data sample displayed by the previous Code cell does not indicate any problems with the data that must be fixed, but to ensure the data are clean, we first check if there's missing data with DataFrame `info` function, then compute and display summary statistics by using the `describe` function.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 15 columns):\n",
      "Age               4000 non-null int64\n",
      "Workclass         4000 non-null object\n",
      "FNLWGT            4000 non-null int64\n",
      "Education         4000 non-null object\n",
      "EducationLevel    4000 non-null int64\n",
      "MaritalStatus     4000 non-null object\n",
      "Occupation        4000 non-null object\n",
      "Relationship      4000 non-null object\n",
      "Race              4000 non-null object\n",
      "Sex               4000 non-null object\n",
      "CapitalGain       4000 non-null int64\n",
      "CapitalLoss       4000 non-null int64\n",
      "HoursPerWeek      4000 non-null int64\n",
      "NativeCountry     4000 non-null object\n",
      "Salary            4000 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information of the adult data shows that there's no missing data in all columns. Next we check the descriptive statistics of numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>FNLWGT</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>38.463500</td>\n",
       "      <td>1.888918e+05</td>\n",
       "      <td>10.057750</td>\n",
       "      <td>1087.994500</td>\n",
       "      <td>86.308500</td>\n",
       "      <td>40.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>13.778775</td>\n",
       "      <td>1.075761e+05</td>\n",
       "      <td>2.564383</td>\n",
       "      <td>7633.716387</td>\n",
       "      <td>401.559989</td>\n",
       "      <td>12.427693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.487800e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.167880e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783395e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.345628e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.268339e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age        FNLWGT  EducationLevel   CapitalGain  CapitalLoss  \\\n",
       "count  4000.000000  4.000000e+03     4000.000000   4000.000000  4000.000000   \n",
       "mean     38.463500  1.888918e+05       10.057750   1087.994500    86.308500   \n",
       "std      13.778775  1.075761e+05        2.564383   7633.716387   401.559989   \n",
       "min      17.000000  1.487800e+04        1.000000      0.000000     0.000000   \n",
       "25%      27.000000  1.167880e+05        9.000000      0.000000     0.000000   \n",
       "50%      37.000000  1.783395e+05       10.000000      0.000000     0.000000   \n",
       "75%      47.000000  2.345628e+05       12.000000      0.000000     0.000000   \n",
       "max      90.000000  1.268339e+06       16.000000  99999.000000  4356.000000   \n",
       "\n",
       "       HoursPerWeek  \n",
       "count   4000.000000  \n",
       "mean      40.413000  \n",
       "std       12.427693  \n",
       "min        1.000000  \n",
       "25%       40.000000  \n",
       "50%       40.000000  \n",
       "75%       45.000000  \n",
       "max       99.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display descriptive statistics\n",
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "The descriptive statistics indicate that the numerical columns all contain valid data, and that the ranges seem to be  reasonable. At this point, in a real world problem we would also explore the categorical features, for example, checking count of distinct values in a categorical column. In this case, however, we can proceed to the next step, where we define our label feature. This data is generally used to test classification algorithms, as the data include a _Salary_ column that includes one of two entries: `<=50K` or `>50K` to indicate if the individual's salary is less than or equal to \\\\$50,000 or if the individual's salary exceeds \\\\$50,000. \n",
    "\n",
    "To apply a machine learning algorithm to these data, we need to generate a numerical label that maps to these two values. For this, we create a new column in our DataFrame called `Label` and map the original column to $1$ if the `Salary` feature is equal to `>50K` and $0$ otherwise. This step is done in the following Code cell, where we map a lambda function onto the `Salary` feature to create this new feature. You can also use `LabelEncoder` introduced in the previous lesson. But `LabelEncoder` maps categorical values to numbers based on alphabetical order. In this case we use `map` function to explicitly map `'<=50K'` to 0 and `'>50K'` to 1. The second Code cell compares the original `Salary` feature to our new `Label` feature by randomly sampling five instances to ensure this task was completed successfully.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2223</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3538</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3974</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3358</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Salary  Label\n",
       "583    <=50K      0\n",
       "2223   <=50K      0\n",
       "3538   <=50K      0\n",
       "3974    >50K      1\n",
       "3358    >50K      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label column, one for >50K, zero otherwise.\n",
    "adult_data['Label'] = adult_data['Salary'].map(lambda x : 1 if '>50K' in x else 0)\n",
    "# Display label and original column for comparison\n",
    "adult_data[['Salary', 'Label']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "With our new `Label` feature, we can compute what is known as the _zero model_, in which we classify the data by always predicting the majority class. While we do not do this in practice since the model provides no predictive power or insights into the data, this does set a useful baseline for how well an algorithm should perform. Any model that performs worse or similar to the _zero model_ should be discarded. Instead, we will want to perform better than this value. In this case, the majority class is 0, our zero model performs at a 77.1% classification accuracy, which indicates that our data set is unbalanced since we have roughly three lower salary instances to every higher salary instance.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3084\n",
       "1     916\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of each class in Label column\n",
    "adult_data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Model Performance = 77.1%\n"
     ]
    }
   ],
   "source": [
    "#zero model\n",
    "zm = float(adult_data.Label.value_counts()[0]/(adult_data.Label.value_counts()[0]+adult_data.Label.value_counts()[1]))\n",
    "print(f'Zero Model Performance = {100.0 * zm:4.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "With our target label constructed, we now create the independent and dependent variables that we will use to construct the logistic regression model. \n",
    "\n",
    "In the following Code cell, we use patsy model to create independent and dependent variables. We select 4 columns as the independent variable. Among them, `Age`, `HoursPerWeek` and `CapitalGain` are continous features, `Sex` is categorical feature.\n",
    "\n",
    "Feature selection is an important topic and we will discuss it in more details in future lessons. For now we will just pick these columns for demonstration purpose.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy as pts \n",
    "\n",
    "# Create dependent and independent variables\n",
    "y, x = pts.dmatrices('Label ~ Age + HoursPerWeek + CapitalGain + C(Sex)', data=adult_data, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>C(Sex)[T. Male]</th>\n",
       "      <th>Age</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>CapitalGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  C(Sex)[T. Male]   Age  HoursPerWeek  CapitalGain\n",
       "0        1.0              1.0  62.0          40.0          0.0\n",
       "1        1.0              1.0  50.0          40.0          0.0\n",
       "2        1.0              1.0  36.0          50.0          0.0\n",
       "3        1.0              0.0  64.0          40.0          0.0\n",
       "4        1.0              1.0  28.0          60.0          0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### LogisticRegression Model\n",
    "\n",
    "With our feature and label data prepared, we are now ready to begin the machine learning process. In the following two Code cells we first create our logistic regression classifier, and then measure its performance on our training data. In the first Code cell, we start by splitting our data into training and testing samples. Since we have over 30,000 instances in our data set, our standard 60%:40% split should be sufficient. Next, we create the `LogisticRegression` estimator. The only hyperparameter that we specify at this time is  `C` in order to reduce the impact of regularization. Next, we fit this estimator to our training data, and generate an accuracy score on our test data. \n",
    "\n",
    "In the second Code cell, we compute and display a simple accuracy score before generating and displaying the full classification report. In the next code cells, we define a function `confusion`, then use the function to plot the confusion matrix. Our logistic regression performs a little better than the zero model. The report indicates that our model performs worst in predicting the high income class(or 1). Specifically, the low recall rate of high income(class 0) indicates that we incorrectly label majority of high income targets as low income. This could prove problematic, for example, if we are seeking to target high wage earners in a marketing campaign.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=23)\n",
    "\n",
    "adult_model = LogisticRegression(C=1E6)\n",
    "adult_model = adult_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression [Adult Data] Score = 79.0%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.98      0.88      1211\n",
      "         1.0       0.74      0.21      0.33       389\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.77      0.59      0.60      1600\n",
      "weighted avg       0.78      0.79      0.74      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Classify test data and display score and report\n",
    "predicted = adult_model.predict(x_test)\n",
    "score = 100.0 * metrics.accuracy_score(y_test, predicted)\n",
    "print(f'Logistic Regression [Adult Data] Score = {score:4.1f}%\\n')\n",
    "print('Classification Report:')\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method produces a colored heatmap that displays the relationship\n",
    "# between predicted and actual types from a machine learning method.\n",
    "\n",
    "def confusion(test, predict, labels, title='Confusion Matrix'):\n",
    "    '''\n",
    "        test: true label of test data, must be one dimensional\n",
    "        predict: predicted label of test data, must be one dimensional\n",
    "        labels: list of label names, ie: ['positive', 'negative']\n",
    "        title: plot title\n",
    "    '''\n",
    "\n",
    "    bins = len(labels)\n",
    "    # Make a 2D histogram from the test and result arrays\n",
    "    pts, xe, ye = np.histogram2d(test, predict, bins)\n",
    "\n",
    "    # For simplicity we create a new DataFrame\n",
    "    pd_pts = pd.DataFrame(pts.astype(int), index=labels, columns=labels )\n",
    "    \n",
    "    # Display heatmap and add decorations\n",
    "    hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")    \n",
    "    hm.axes.set_title(title, fontsize=20)\n",
    "    hm.axes.set_xlabel('Predicted', fontsize=18)\n",
    "    hm.axes.set_ylabel('Actual', fontsize=18)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion(y_test['Label'], predicted, ['low', 'high'], title='Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21079691516709512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 82/(307+82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Classification Performance Metrics\n",
    "\n",
    "There are many ways to measure the performance of a classification model. In above code, to evaluate the model, we printed the accuracy score, the classification report which has precision, recall and f1-score, and plotted the confusion matrix. We will discuss these terms briefly below.\n",
    "\n",
    "Classification performance metrics are very import concept, we will explore them in more details in future lessons.\n",
    "\n",
    "#### Accuracy Score\n",
    "Accuracy score is the proportion of correct predictions.  \n",
    "From the confusion matrix, the correct low income prediction is 1182, correct high income prediction is 82, so the accuracy score is (1182 + 82)/(1182+82+307+29)=0.79.\n",
    "\n",
    "#### Precision\n",
    "Precision is the proportion of the prediction that is actually correct.  \n",
    "From the confusion matrix, 1182+307 are predicted as low income, among them, 1182 are actual low income, so the precision of low income(or 0) is 1182/(1182+307)=0.79.  \n",
    "Precision of high income(or 1) is 82/(82+29)= 0.74. \n",
    "\n",
    "#### Recall\n",
    "Recall is the proportion of actual class of a label that is identified correctly.\n",
    "From the confusion matrix, actual number of low income is 1182+2, among them 1182 are correcly identified as low income, so the recall of low income(or 0) is 1182/(1182+29)=0.98.  \n",
    "Recall of high income(or 1) is 82/(307+82)=0.21\n",
    "\n",
    "#### f1-score\n",
    "f1-score is harmonic mean of Precision and Recall.  \n",
    "The low f1-score on high income(or 1) indicates that the model did a bad job on predicting high income.\n",
    "\n",
    "#### support\n",
    "Support is the number of occurrences of each particular class in the true responses (responses in your test set). You can calculate it by summing the columns of the confusion matrix.\n",
    "\n",
    "#### Confusion Matrix\n",
    "A confusion matrix is a specific table layout that allows visualization of the performance of an algorithm.\n",
    "\n",
    "In the confusion matrix above, y axis represents actual values of test label and x axis represents predicted values.  \n",
    "The first row of the confusion matrix shows count of true low income, which is 1182 + 29, among which 1182 are correctly predicted as low income and 29 are wrongly predicted as high income.  \n",
    "The second row of the confusion matrix shows count of true high income, which is 307 + 82, among which 307 are wrongly predicted as low income and 82 are correctly predicted as high income.\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cells, we used logistic regression to predict if a person earns high income or low income from the `Age`, `HoursPerWeek`, `CapitalGain` and categorical `Sex` features. In the empty **Code** cell below, repeat this process, but add more features to independent variables, ie. `Relationship` or `Race`. Has the prediction performance improved?\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Ancillary Information\n",
    "\n",
    "The following links are to additional documentation that you might find helpful in learning this material. Reading these web-accessible documents is completely optional.\n",
    "\n",
    "1. Wikipedia article on [Logistic Regression][1]\n",
    "1. An interesting blog article on performing [logistic regression][2] in Python\n",
    "2. An implementation of [logistic regression][3] for modeling usage of wells in remote locations\n",
    "5. A demonstration of logistic regression for [loan prediction][6]\n",
    "67. A concise discussion on [performance metrics][pm] for classification algorithms\n",
    "-----\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Logistic_regression\n",
    "[2]: http://blog.yhat.com/posts/logistic-regression-and-python.html\n",
    "[3]: http://slendermeans.org/arm-ch5.html\n",
    "[6]: http://nbviewer.jupyter.org/github/nborwankar/LearnDataScience/blob/master/notebooks/B3.%20Logistic%20Regression%20-%20Analysis.ipynb\n",
    "[pm]: http://mrvar.fdv.uni-lj.si/pub/mz/mz3.1/vuk.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2019: Gies College of Business at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Logistic Regression\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous notebooks, we have seen how to perform linear regression on input data to predict a continuous value. In some cases, however, we wish to predict a categorical value, such as _True/False_ or _Yes/No_. Traditional regression methods are not optimal for these problems, since this requires the prediction of a discrete and not continuous value. In this notebook we introduce a technique that simulates linear regression, but with an additional function employed that maps the continuous value predicted by linear regression methods into a **probability**, or specifically the range $[0, 1]$. In this manner, we can apply a threshold to this probability to predict a binary response.\n",
    "\n",
    "While several functions might be suitable for this transformation, the most popular\n",
    "function is the [_logit_ function][wlf]. Note that some older analyses might reference the [_probit_ function][wpf]. Performing regression by using the logit function is known as [logistic regression][wlr] (the inverse of the logit function is known as the [_logistic_ function][wlcf]). The name might seem confusing since technically this algorithm is used to perform classification, but since logistic regression borrows heavily in its approach from linear regression, the descriptive name was maintained. A major benefit of logistic regression is the creation of a parametric model that can be explored to understand why predictions are made, in the same manner as a linear regression model.\n",
    "\n",
    "In this notebook, we introduce the logit function and how it can be used to construct a binary model. Next, we introduce logistic regression, and specifically show how logistic regression can be performed by using estimators from the scikit-learn library. We also introduce several popular performance metrics and show how they can be calculated for binary classification tasks. We demonstrate logistic regression on several data sets, including one that contains categorical features. We also demonstrate how to perform logistic regression by using the statsmodels module with a formula interface, and introduce how to use this same formula interface with scikit-learn estimators. Finally, we discuss topics such as marginal effects and odds ratios, which are concepts that often prove useful in interpreting logistic regression models.\n",
    "\n",
    "-----\n",
    "[wlr]: https://en.wikipedia.org/wiki/Logistic_regression\n",
    "[wlf]: https://en.wikipedia.org/wiki/Logit\n",
    "[wpf]: https://en.wikipedia.org/wiki/Probit\n",
    "[wlcf]: https://en.wikipedia.org/wiki/Logistic_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Formalism](#Formalism)\n",
    "\n",
    "- [Logit Function](#Logit-Function)\n",
    "- [Gradient Descent](#Gradient-Descent)\n",
    "- [Logistic Modelling](#Logistic-Modelling)\n",
    "\n",
    "[Logistic Regression: Adult Data](#LogisticRegression:-Adult-Data)\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [LogisticRegression Model](#LogisticRegression-Model)\n",
    "- [Performance Metrics](#Performance-Metrics)\n",
    "\n",
    "[SGD Classifier](#SGD-Classifier)\n",
    "\n",
    "-----\n",
    "\n",
    "Before proceeding with the _Formalism_ section of this Notebook, we first have our standard notebook setup code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We do this to ignore several specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Formalism\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a binary classification process, we have two possible outcomes, which for the sake of generality, we can label as _Success_ or _Failure_. Denoting the probability of these two outcomes as $P(S)$ and $P(F)$ respectively, we can write the probability of success as $P(S) = p$, and the probability of failure as $P(F) = 1 - p$. Thus, the odds of a successful outcome, which is the ratio of the probability of success to the probability of failure, is given by the following expression:\n",
    "\n",
    "$\\textrm{Odds}(S) = \\frac{p}{1 - p}$\n",
    "\n",
    "We can extend the framework of _linear regression_ to the task of binary classification by employing a mapping between the continuous value predicted by a linear regressor and the probability of an event occurring, which is bounded by the range $[0, 1]$. To do this, we need a function that maps the real numbers into this range, which enables a regression onto a set of discrete values (0 or 1) that provides us the binary classification. One popular choice for this function is the _logit_ function, while another choice is the _probit_ function. The use of these functions for a classification task leads to _logistic regression_ or _probit regression_. While we focus in this notebook on the application of logistic regression for the binary classification task, this approach can be generalized to classify into more than two categories, this more advanced technique is known as [multinomial logistic regression][mlr].\n",
    "\n",
    "-----\n",
    "\n",
    "[mlr]: https://en.wikipedia.org/wiki/Multinomial_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Logit Function\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\DeclareMathOperator\\erf{erf}$\n",
    "\n",
    "The [_logit_ function][wl] is defined as the logarithm of the odds (i.e, $p/(1 - p)$), which is also known as the _log-odds_. Thus, the _logit_ function can be written for a probability of success $p$:\n",
    "\n",
    "$\\textrm{logit}(p) = \\log\\left(\\frac{p}{1 - p}\\right)$ where $0 \\leq p \\leq 1$. \n",
    "\n",
    "We can invert this relationship to obtain the [_logistic_ function][wlf], which for a parameter $\\alpha$ is defined by the following expression:\n",
    "\n",
    "$\\textrm{logit}^{-1}(\\alpha) = \\textrm{logistic}(\\alpha) = \\frac{1}{1 + \\exp{(-\\alpha})}$\n",
    "\n",
    "While the logistic function is most commonly used to perform this type of regression, a related function is the [_probit_ function][wp], which stands for _probability unit_ and is sometimes used in lieu of the _logit_ function. The _probit_ function is defined for a probability of success, $p$:\n",
    "\n",
    "$\\textrm{probit}(p) = \\sqrt{2}\\erf^{-1}(2p - 1)$ where $0 \\leq p \\leq 1$, and $\\erf$ is the [Error Function][wef].\n",
    "\n",
    "The logit function (and the probit function) is an _S_ shaped curve that converts real numbers into a probability. Both the logit and probit functions are related to the *sigmoid* function, but are centered at the origin (0, 0). For the rest of this notebook, we will only consider the $\\textrm{logit}$ function. In the following Code cell, we plot the $\\textrm{logistic}$ function, or the inverse of the logit function, demonstrating how the real numbers can be mapped into the range $[0, 1]$.\n",
    "\n",
    "-----\n",
    "[wl]: https://en.wikipedia.org/wiki/Logit\n",
    "[wp]: https://en.wikipedia.org/wiki/Probit\n",
    "[wlf]: https://en.wikipedia.org/wiki/Logistic_function\n",
    "[wef]: https://en.wikipedia.org/wiki/Error_function\n",
    "[mlr]: https://en.wikipedia.org/wiki/Multinomial_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Compute and plot logistic function\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = 1. / (1 + np.exp(-x))\n",
    "ax.plot(x, y, alpha=0.75)\n",
    "\n",
    "# Draw probability barrier\n",
    "ax.hlines(0.5, -10, 10, linestyles='--')\n",
    "\n",
    "# Decorate plot\n",
    "ax.set_xlabel(r'$\\alpha$', fontsize=16)\n",
    "ax.set_ylabel(r'$p$', fontsize=16)\n",
    "ax.set_title('Logistic Function', fontsize=18)\n",
    "sns.despine(offset = 2, trim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "-----\n",
    "\n",
    "Given the previously defined _logistic_ function, we can develop the formalism of _logistic regression_ by first employing a linear regression model to predict a dependent variable from the set of independent features. Second, we apply the logistic function to the dependent variable in the linear regression model to make our binary classification prediction. Thus, if we have the following linear model:\n",
    "\n",
    "$ y = mx + b$\n",
    "\n",
    "the logistic regression model fits the following logistic model:\n",
    "\n",
    "$ \\textrm{logistic}(y) = \\frac{1}{1 + \\exp(-y)}$\n",
    "\n",
    "The generally used cost (or loss) function for logistic regression is the sum of the squared errors between the actual classes and the predicted classes. One of the most popular techniques for finding the minimum of this cost function is to use [_stochastic gradient descent_][wsgd]. [Gradient descent][wgd] computes the derivate of (or finds the slope of the tangent line to) the cost function at a particular point. This can be used to modify the parameters of our model to move in a direction that is expected to reach the minimum of the cost function. Standard gradient descent computes these corrections by summing up all the contributions from each training data point. In stochastic gradient descent (or **SGD**), however, the corrections are computed for each training point. As a result, SGD often generates a path towards the minimum that is somewhat rambling, but this has the benefit of avoiding local minima and being more robust.\n",
    "\n",
    "----\n",
    "[wgd]: https://en.wikipedia.org/wiki/Gradient_descent\n",
    "[wsgd]: https://en.wikipedia.org/wiki/Stochastic_gradient_descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "The scikit-learn library has a standard `LogisticRegression` and an `SGDRegression` estimator. In this notebook, we demonstrate both estimators; however, the latter is a general technique that uses SGD to minimize the cost function. By specifying the `log` value to the `loss` hyperparameter, we can use the `SGDRegression` estimator to perform logistic regression. This can be very useful, especially in a teaching situation, since, by default, the `LogisticRegression` estimator performs regularization, which we have not yet covered (but will in a later notebook). Regularization is a technique to minimize the likelihood of over-fitting and works by penalizing complex models, which, in effect, alters the coefficients of our logistic regression model. \n",
    "\n",
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Logistic Modelling\n",
    "\n",
    "Before introducing logistic regression, we first show how the logistic function can be used to model binary response data. For this purpose, we will use data from NASA on the relationship between the outside temperature when the space shuttle was launched, and the occurrence of a thermal failure of an O-ring on a booster rocket. We will use this data to create a predictive model between temperature and thermal failure; note that it is believed that the [failure of an O-ring][wsrb] on a solid rocket booster led to the Challenger disaster.\n",
    "\n",
    "We will bypass the logistic regression process and instead explain the concept with two images. The first image is the O-ring test result conducted by NASA. The test recorded the number of O-ring failures under different temperature. The [actual data][ord] we use is hosted at the University of California at Irvine (UCI) machine learning data repository.\n",
    "\n",
    "<img src=\"images/oring.png\" width=\"600\">\n",
    "\n",
    "We can apply logistic regression on this data. The independent variable is temperature. The dependent variable will be whether there's at least one failure, 1 if yes, 0 if no.\n",
    "\n",
    "After we apply logistic function and minimize the cost function, we will get a sigmoid curve which is also our predictive model like this:\n",
    "\n",
    "<img src=\"images/sigmoid.png\" width=\"600\">\n",
    "\n",
    "\n",
    "-----\n",
    "[wsrb]: https://en.wikipedia.org/wiki/Space_Shuttle_Solid_Rocket_Booster#Challenger_disaster\n",
    "[ord]: https://archive.ics.uci.edu/ml/machine-learning-databases/space-shuttle/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given this predictive model, we can predict for new, unseen data. In this case, we can predict the probability of thermal failure for a given temperature. We can see that the probability of at least one O-ring failure is about 50% when temperature is 65 degree. The temperature at launch during the Challenger disaster was 31 degrees Fahrenheit!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## LogisticRegression: Adult Data\n",
    "\n",
    "-----\n",
    "\n",
    "We now will use the `LogisticRegression` estimator in the scikit-learn library to construct a logistic regression model. This estimator accepts a number of hyperparameters, of which the most important for our purposes include:\n",
    "\n",
    "- `C`: inverse of regularization strength\n",
    "- `class_weight`: weights to be applied to classes when performing regression, default is uniform\n",
    "- `penalty`: type of regularization to be applied, can be `l1` or `l2`, both of which will be discussed in a future notebook\n",
    "- `fit_intercept`: specifies if a constant term should be included in the regression, the default is `True`\n",
    "- `random_state`: the seed used to initialize the random number generator, a constant value ensures reproducibility.\n",
    "\n",
    "Run help(LogisticRegression) to view more details about the model and the hyper parameters.\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=1E6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "We now turn to a more complex data set with which to perform logistic regression. The data we will explore next is the [Adult income prediction task][uciad]. These data were extracted by Barry Becker from the 1994 Census database and consist of the following features: age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, and salary. Of these, only five are continuous:  fnlwgt, education-num, capital-gain, capital-loss, and hours-per-week, the others are discrete. The last column, salary, is discrete and contains one of two strings to indicate if the salary was below or above $50,000. This is the column we will use to make our label.\n",
    "\n",
    "We first use the pandas `read_csv` function to read the data file from UCI Machine Learning Repository. We explicitly define the column names. Once the DataFrame is created, we randomly sample five rows to verify that the data has been successfully read.\n",
    "\n",
    "Next, we display basic information and descriptive statistics of the dataframe to get more understanding of our data.\n",
    "\n",
    "Next, we encode out target column `Salary` to create a numeric label. We use `value_counts()` to check class balance of the label.\n",
    "\n",
    "Finally, we use patsy module to create dependent and independent variables from the dataframe.\n",
    "\n",
    "-----\n",
    "[uciad]: https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>FNLWGT</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22849</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>115443</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>185520</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>8614</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>330695</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16715</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>183850</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Workclass  FNLWGT      Education  EducationLevel  \\\n",
       "19984   36   Private  374983           11th               7   \n",
       "22849   18   Private  115443           11th               7   \n",
       "2713    39   Private  185520   Some-college              10   \n",
       "5056    26   Private  330695   Some-college              10   \n",
       "16715   41   Private  183850        HS-grad               9   \n",
       "\n",
       "             MaritalStatus          Occupation    Relationship    Race  \\\n",
       "19984   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "22849   Married-civ-spouse        Craft-repair         Husband   White   \n",
       "2713              Divorced     Exec-managerial   Not-in-family   White   \n",
       "5056    Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "16715             Divorced               Sales   Not-in-family   White   \n",
       "\n",
       "           Sex  CapitalGain  CapitalLoss  HoursPerWeek   NativeCountry  Salary  \n",
       "19984     Male            0            0            40   United-States   <=50K  \n",
       "22849     Male            0            0            40   United-States   <=50K  \n",
       "2713    Female         8614            0            40   United-States    >50K  \n",
       "5056      Male            0            0            40   United-States   <=50K  \n",
       "16715     Male            0            0            50   United-States   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adult data archived at UCI ML Repository\n",
    "\n",
    "data_file = \"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "col_names = ['Age', 'Workclass', 'FNLWGT', 'Education', \n",
    "             'EducationLevel', 'MaritalStatus', 'Occupation', \n",
    "             'Relationship', 'Race', 'Sex', 'CapitalGain', 'CapitalLoss', \n",
    "             'HoursPerWeek', 'NativeCountry', 'Salary']\n",
    "\n",
    "# Read CSV data from URL return Pandas\n",
    "adult_data = pd.read_csv(data_file, index_col=False, names = col_names)\n",
    "\n",
    "# Display random sample\n",
    "adult_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "The data sample displayed by the previous Code cell does not indicate any problems with the data that must be fixed, but to ensure the data are clean, we first check if there's missing data with DataFrame `info` function, then compute and display summary statistics by using the `describe` function.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "Age               32561 non-null int64\n",
      "Workclass         32561 non-null object\n",
      "FNLWGT            32561 non-null int64\n",
      "Education         32561 non-null object\n",
      "EducationLevel    32561 non-null int64\n",
      "MaritalStatus     32561 non-null object\n",
      "Occupation        32561 non-null object\n",
      "Relationship      32561 non-null object\n",
      "Race              32561 non-null object\n",
      "Sex               32561 non-null object\n",
      "CapitalGain       32561 non-null int64\n",
      "CapitalLoss       32561 non-null int64\n",
      "HoursPerWeek      32561 non-null int64\n",
      "NativeCountry     32561 non-null object\n",
      "Salary            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information of the adult data shows that there's no missing data in all columns. Next we check the descriptive statistics of numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>FNLWGT</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age        FNLWGT  EducationLevel   CapitalGain   CapitalLoss  \\\n",
       "count  32561.000000  3.256100e+04    32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05       10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05        2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04        1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05        9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05       10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05       12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06       16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       HoursPerWeek  \n",
       "count  32561.000000  \n",
       "mean      40.437456  \n",
       "std       12.347429  \n",
       "min        1.000000  \n",
       "25%       40.000000  \n",
       "50%       40.000000  \n",
       "75%       45.000000  \n",
       "max       99.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display descriptive statistics\n",
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "The descriptive statistics indicate that the numerical columns all contain valid data, and that the ranges seem to be  reasonable. At this point, in a real world problem we would also explore the categorical features, for example, checking count of distinct values in a categorical column. In this case, however, we can proceed to the next step, where we define our label feature. This data is generally used to test classification algorithms, as the data include a _Salary_ column that includes one of two entries: `<=50K` or `>50K` to indicate if the individual's salary is less than or equal to \\\\$50,000 or if the individual's salary exceeds \\\\$50,000. \n",
    "\n",
    "To apply a machine learning algorithm to these data, we need to generate a numerical label that maps to these two values. For this, we create a new column in our DataFrame called `Label` and map the original column to $1$ if the `Salary` feature is equal to `>50K` and $0$ otherwise. This step is done in the following Code cell, where we map a lambda function onto the `Salary` feature to create this new feature. The second Code cell compares the original `Salary` feature to our new `Label` feature by randomly sampling twelve instances to ensure this task was completed successfully.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10362</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28966</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27004</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29341</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32158</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Salary  Label\n",
       "2701    <=50K      0\n",
       "6963    <=50K      0\n",
       "10362    >50K      1\n",
       "8135    <=50K      0\n",
       "4488    <=50K      0\n",
       "28966    >50K      1\n",
       "4695    <=50K      0\n",
       "27004   <=50K      0\n",
       "29341    >50K      1\n",
       "32158   <=50K      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label column, one for >50K, zero otherwise.\n",
    "adult_data['Label'] = adult_data['Salary'].map(lambda x : 1 if '>50K' in x else 0)\n",
    "# Display label and original column for comparison\n",
    "adult_data[['Salary', 'Label']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "With our new `Label` feature, we can compute what is known as the _zero model_, in which we classify the data by always predicting the majority class. While we do not do this in practice since the model provides no predictive power or insights into the data, this does set a useful baseline for how well an algorithm should perform. Any model that performs worse or similar to the _zero model_ should be discarded. Instead, we will want to perform better than this value. In this case, the majority class is 0, our zero model performs at a 75.9% classification accuracy, which indicates that our data set is unbalanced since we have roughly three lower salary instances to every higher salary instance.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of each class in Label column\n",
    "adult_data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Model Performance = 75.9%\n"
     ]
    }
   ],
   "source": [
    "#zero model\n",
    "zm = float(adult_data.Label.value_counts()[0]/(adult_data.Label.value_counts()[0]+adult_data.Label.value_counts()[1]))\n",
    "print(f'Zero Model Performance = {100.0 * zm:4.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "With our target label constructed, we now create the independent and dependent variables that we will use to construct the logistic regression model. \n",
    "\n",
    "In the following Code cell, we use patsy model to create independent and dependent variables. We select 4 columns as the independent variable. Among them, `Age`, `HoursPerWeek` and `CapitalGain` are continous features, `Sex` is categorical feature.\n",
    "\n",
    "Feature selection is an important topic and we will discuss it in more details in future lessons. For now we will just pick these columns for demonstration purpose.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy as pts \n",
    "\n",
    "# Create dependent and independent variables\n",
    "y, x = pts.dmatrices('Label ~ Age + HoursPerWeek + CapitalGain + C(Sex)', data=adult_data, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>C(Sex)[T. Male]</th>\n",
       "      <th>Age</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>CapitalGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  C(Sex)[T. Male]   Age  HoursPerWeek  CapitalGain\n",
       "0        1.0              1.0  39.0          40.0       2174.0\n",
       "1        1.0              1.0  50.0          13.0          0.0\n",
       "2        1.0              1.0  38.0          40.0          0.0\n",
       "3        1.0              1.0  53.0          40.0          0.0\n",
       "4        1.0              0.0  28.0          40.0          0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### LogisticRegression Model\n",
    "\n",
    "With our feature and label data prepared, we are now ready to begin the machine learning process. In the following two Code cells we first create our logistic regression classifier, and then measure its performance on our training data. In the first Code cell, we start by splitting our data into training and testing samples. Since we have over 30,000 instances in our data set, our standard 60%:40% split should be sufficient. Next, we create the `LogisticRegression` estimator. The only hyperparameter that we specify at this time is  `C` in order to reduce the impact of regularization. Next, we fit this estimator to our training data, and generate an accuracy score on our test data. \n",
    "\n",
    "In the second Code cell, we compute and display a simple accuracy score before generating and displaying the full classification report. In the next code cells, we define a function `confusion`, then use the function to plot the confusion matrix. Our logistic regression performs just a little better than the zero model. The report indicates that our model performs worst in predicting the high income class(or 1). Specifically, the recall rate of high income  indicates that we incorrectly label majority of high income targets as low income. This could prove problematic, for example, if we are seeking to target high wage earners in a marketing campaign.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=23)\n",
    "\n",
    "adult_model = LogisticRegression(C=1E6)\n",
    "adult_model = adult_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression [Adult Data] Score = 78.9%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.97      0.87      9811\n",
      "         1.0       0.71      0.25      0.37      3214\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     13025\n",
      "   macro avg       0.75      0.61      0.62     13025\n",
      "weighted avg       0.78      0.79      0.75     13025\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Classify test data and display score and report\n",
    "predicted = adult_model.predict(x_test)\n",
    "score = 100.0 * metrics.accuracy_score(y_test, predicted)\n",
    "print(f'Logistic Regression [Adult Data] Score = {score:4.1f}%\\n')\n",
    "print('Classification Report:\\n {0}\\n'.format(metrics.classification_report(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method produces a colored heatmap that displays the relationship\n",
    "# between predicted and actual types from a machine learning method.\n",
    "\n",
    "def confusion(test, predict, labels, title='Confusion Matrix'):\n",
    "    '''\n",
    "        test: true label of test data, must be one dimensional\n",
    "        predict: predicted label of test data, must be one dimensional\n",
    "        labels: list of label names, ie: ['positive', 'negative']\n",
    "        title: plot title\n",
    "    '''\n",
    "\n",
    "    bins = len(labels)\n",
    "    # Make a 2D histogram from the test and result arrays\n",
    "    pts, xe, ye = np.histogram2d(test, predict, bins)\n",
    "\n",
    "    # For simplicity we create a new DataFrame\n",
    "    pd_pts = pd.DataFrame(pts.astype(int), index=labels, columns=labels )\n",
    "    \n",
    "    # Display heatmap and add decorations\n",
    "    hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")    \n",
    "    hm.axes.set_title(title, fontsize=20)\n",
    "    hm.axes.set_xlabel('Predicted', fontsize=18)\n",
    "    hm.axes.set_ylabel('Actual', fontsize=18)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion(y_test['Label'], predicted, ['low', 'high'], title='Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "Classification report must be straightforward - a report of Precision/Recal/F1-score for each element in your test data. In Multiclass problems, it is not a good idea to read Precision/Recall and F-Measure over the whole data. Any imbalance would make you feel you've reached better results. Coming to confusion matrix, it is much detailed representation of what's going on with your labels.\n",
    "\n",
    "#### Confusion Matrix\n",
    "A confusion matrix is a specific table layout that allows visualization of the performance of an algorithm.\n",
    "\n",
    "In the confusion matrix above, y axis represents actual values of test label and x axis represents predicted values.  \n",
    "The first row of the confusion matrix shows count of low income, which is 9491 + 324, among which 9491 are correctly predicted as low income and 320 are wrongly predicted as high income.  \n",
    "The second row of the confusion matrix shows count of high income, which is 2425 + 789, among which 2425 are wrongly predicted as low income and 789 are correctly predicted as high income.\n",
    "\n",
    "#### Accuracy Score\n",
    "Accuracy score is the proportion of correct predictions.  \n",
    "From the confusion matrix, the correct low income prediction is 9491, correct high income prediction is 789, so the accuracy score is (9491+789)/(9491+789+320+2425)=0.789.\n",
    "\n",
    "#### Precision\n",
    "Precision is the proportion of the prediction that is actually correct.  \n",
    "From the confusion matrix, 9491 + 2425 are predicted as low income, among them, 9491 are actually low income, so the precision of low income(or 0) is 9491/(9491+2425)=0.8.  \n",
    "Precision of high income(or 1) is 789/(320+789)= 0.71. \n",
    "\n",
    "#### Recall\n",
    "Recall is the proportion of actual class of a label that is identified correctly.\n",
    "From the confusion matrix, actual number of low income is 9491+320, among them 9491 are correcly identified as low income, so the recall of low income(or 0) is 9491/(9491+320)=0.97.  \n",
    "Recall of high income(or 1) is 789/(2425+789)=0.25\n",
    "\n",
    "#### f1-score\n",
    "f1-score is harmonic mean of Precision and Recall.  \n",
    "The low f1-score on high income(or 1) indicates that the model did a bad job on predicting high income.\n",
    "\n",
    "#### support\n",
    "Support is the number of occurrences of each particular class in the true responses (responses in your test set). You can calculate it by summing the columns of the confusion matrix.\n",
    "\n",
    "We will discuss these performence metrics and how to improve the model in more detail in future lessons.\n",
    "\n",
    "-----\n",
    "[wcm]: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "[skm]: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "[wht]: https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cells, we used logistic regression to predict if a person earns high income or low income from the `Age`, `HoursPerWeek`, `CapitalGain` and categorical `Sex` features. In the empty **Code** cell below, repeat this process, but add more features to independent variables, ie. `Relationship` or `Race`. Has the prediction performance improved?\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## SGD Classifier\n",
    "\n",
    "We now turn to the alternative technique for performing logistic regression with the scikit-learn library. We can employ a stochastic gradient descent classifier to perform logistic regression by specifying a logarithmic `loss` function (or cost function in our previous terminology). This has several benefits over the standard logistic regression estimator in the scikit-learn library. First, this technique employs stochastic gradient descent, which can be efficient in finding the minimum of the cost function, especially with large and complex data sets. Stochastic gradient descent is based on standard gradient descent that was demonstrated graphically earlier, but is less prone to being trapped in local minima (or valleys).\n",
    "\n",
    "Second, this estimator does not automatically employ regularization, a technique designed to reduce overfitting. The standard logistic regression estimator employs the `C` hyperparameter to control the amount of regularization used to minimize the cost function.\n",
    "\n",
    "The following Code cell demonstrates the use of the `SGDClassifier` with a logarithmic loss function to perform logistic regression on the adult data. As the output displays, the results are worse than those from the standard logistic regression estimator when we minimized the effects of regularization.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier Score = 77.6%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.96      0.87      9811\n",
      "         1.0       0.63      0.22      0.33      3214\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     13025\n",
      "   macro avg       0.71      0.59      0.60     13025\n",
      "weighted avg       0.75      0.78      0.73     13025\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Create SGD estimor with log loss\n",
    "sgd_model = SGDClassifier(loss='log', random_state=2)\n",
    "\n",
    "# Fit training data and predict for test data\n",
    "sgd_model = sgd_model.fit(x_train, y_train)\n",
    "predicted = sgd_model.predict(x_test)\n",
    "\n",
    "# Display performance metrics\n",
    "score = 100.0 * metrics.accuracy_score(y_test, predicted)\n",
    "print(f'SGDClassifier Score = {score:4.1f}%\\n')\n",
    "print('Classification Report:\\n {0}\\n'.format(metrics.classification_report(y_test, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "confusion(y_test['Label'], predicted, ['low', 'high'], title='SGDClassifier')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Ancillary Information\n",
    "\n",
    "The following links are to additional documentation that you might find helpful in learning this material. Reading these web-accessible documents is completely optional.\n",
    "\n",
    "1. Wikipedia article on [Logistic Regression][1]\n",
    "1. An interesting blog article on performing [logistic regression][2] in Python\n",
    "2. An implementation of [logistic regression][3] for modeling usage of wells in remote locations\n",
    "5. A demonstration of logistic regression for [loan prediction][6]\n",
    "67. A concise discussion on [performance metrics][pm] for classification algorithms\n",
    "-----\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Logistic_regression\n",
    "[2]: http://blog.yhat.com/posts/logistic-regression-and-python.html\n",
    "[3]: http://slendermeans.org/arm-ch5.html\n",
    "[6]: http://nbviewer.jupyter.org/github/nborwankar/LearnDataScience/blob/master/notebooks/B3.%20Logistic%20Regression%20-%20Analysis.ipynb\n",
    "[pm]: http://mrvar.fdv.uni-lj.si/pub/mz/mz3.1/vuk.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2019: Gies College of Business at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous notebooks, we split dataset to training and testing set for supervised learning(classification and regression). The training set is used to train the model, while the testing set is used to provide an unbiased evaluation of a model fit on the training set. This approach seems reasonable but there are two problems:\n",
    "1. The training set is only a subset of the available data. The model trained on the training set may fail to adequately capture the characteristics of the whole dataset.\n",
    "2. Similarly, the evaluation metrics are generated based on testing set only. A different split may result in different metric values, making the metrics less reliable.\n",
    "\n",
    "To solve these problems, we introduce [cross-validation][wcv], which is a method that attempts to maximize the use of the available data for training and then testing a model to provide a range of more accurate metrics.\n",
    "\n",
    "We will use adult income data to demonstrate cross-validation.\n",
    "\n",
    "-----\n",
    "\n",
    "[wcv]: https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Data](#Data)\n",
    "\n",
    "[Train-Test Split Approach](#Train-Test-Split-Approach)\n",
    "\n",
    "[Cross Validation](#Cross-Validation)\n",
    "\n",
    "- [KFold](#KFold)\n",
    "- [Stratified KFold](#Stratified-KFold)\n",
    "- [Leave One Out](#Leave-One-Out)\n",
    "- [Leave P Out](#Leave-P-Out)\n",
    "- [Shuffle Split](#Shuffle-Split)\n",
    "- [Group KFold](#Group-KFold)\n",
    "\n",
    "[Evaluate Model with Cross-Validation](#Evaluate-Model-with-Cross-Validation)\n",
    "- [Custom Scorer](#Custom-Scorer)\n",
    "\n",
    "-----\n",
    "\n",
    "Before proceeding with the rest of this notebook, we first have our standard notebook setup code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set default seaborn plotting style\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Data\n",
    "\n",
    "We will use the [adult income data][uciad] throughout this notebook. With the help of feature selection introduced in the previous lesson, we will choose following features as our training features: age, fnlwgt, education-level, marital-status, occupation, relationship, capital-gain, hours-per-week. \n",
    "\n",
    "The following Code cell prepares the data:\n",
    "\n",
    "1. Load data\n",
    "2. Create label from Salary column\n",
    "3. Encode categorical features with string value\n",
    "4. Combine numerical features and encoded categorical features.\n",
    "5. Choose training features\n",
    "\n",
    "-----\n",
    "[uciad]: https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>FNLWGT</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3846</td>\n",
       "      <td>22</td>\n",
       "      <td>351952</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>55</td>\n",
       "      <td>368797</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1658</td>\n",
       "      <td>34</td>\n",
       "      <td>113198</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3415</td>\n",
       "      <td>53</td>\n",
       "      <td>274276</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3678</td>\n",
       "      <td>31</td>\n",
       "      <td>59969</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  FNLWGT  EducationLevel  MaritalStatus  Occupation  Relationship  \\\n",
       "3846   22  351952              10              4          10             4   \n",
       "848    55  368797              14              2           4             0   \n",
       "1658   34  113198              12              2           1             0   \n",
       "3415   53  274276               9              0           1             1   \n",
       "3678   31   59969               9              2           1             2   \n",
       "\n",
       "      CapitalGain  HoursPerWeek  Label  \n",
       "3846            0            20      0  \n",
       "848             0            60      1  \n",
       "1658            0            28      0  \n",
       "3415            0            40      0  \n",
       "3678            0            35      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read CSV data\n",
    "adult_data = pd.read_csv('data/adult_income.csv')\n",
    "\n",
    "# Create label column, one for >50K, zero otherwise.\n",
    "adult_data['Label'] = adult_data['Salary'].map(lambda x : 1 if '>50K' in x else 0)\n",
    "\n",
    "# Generate categorical features(with string values)\n",
    "categorical_features = adult_data[['Workclass', 'Education', 'MaritalStatus', \n",
    "               'Occupation', 'Relationship', 'Race', 'Sex', 'NativeCountry']]\n",
    "\n",
    "#encode categorical features\n",
    "categorical_features = categorical_features.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Extract numerical features\n",
    "numerical_features = adult_data[['Age', 'FNLWGT', 'EducationLevel', 'CapitalGain', 'CapitalLoss', 'HoursPerWeek']]\n",
    "\n",
    "all_features = pd.concat([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "features = all_features[['Age', 'FNLWGT', 'EducationLevel', 'MaritalStatus', 'Occupation', \n",
    "                         'Relationship', 'CapitalGain', 'HoursPerWeek']]\n",
    "\n",
    "label = adult_data['Label']\n",
    "\n",
    "#display sample data\n",
    "pd.concat([features, label], axis=1).sample(5, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Train-Test Split Approach\n",
    "\n",
    "First, we will split the dataset to training and testing as we did before. We will split the dataset twice with different random state, then train a Decision Tree Classifier and compare model accuracy. The reason we choose Decision Tree Classifier is that with Decision Tree: We don't need to create dummy features for categorical features and we don't need to normalize continuous features. Using Decision Tree simplifies data preparation.\n",
    "\n",
    "In the following Code cells, we first create a Decision Tree Classifier, then split the data twice with different random states, train the decision tree classifier with each split, and print out the model accuracy score.\n",
    "\n",
    "From the output, we can see that the same decision tree classifier, trained twice on the same dataset, gives completely different accuracy score. The only reason is that we split the data with different random state. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adult_model = DecisionTreeClassifier(random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification [Adult Data] Score = 81.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "d_train, d_test, l_train, l_test = train_test_split(features, label, test_size=0.4, random_state=0)\n",
    "\n",
    "adult_model = adult_model.fit(d_train, l_train)\n",
    "\n",
    "predicted = adult_model.predict(d_test)\n",
    "score = 100.0 * metrics.accuracy_score(l_test, predicted)\n",
    "print(f'Decision Tree Classification [Adult Data] Score = {score:4.1f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification [Adult Data] Score = 77.7%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_train, d_test, l_train, l_test = train_test_split(features, label, test_size=0.4, random_state=2)\n",
    "\n",
    "adult_model = adult_model.fit(d_train, l_train)\n",
    "\n",
    "predicted = adult_model.predict(d_test)\n",
    "score = 100.0 * metrics.accuracy_score(l_test, predicted)\n",
    "print(f'Decision Tree Classification [Adult Data] Score = {score:4.1f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Cross Validation\n",
    "\n",
    "A preferred way to solve the problems caused by train test split, is to divide the data into multiple segments, or **folds**, hold one segment out for model validation, and using the other folds for training. We can repeat the training and validating by iterating through the folds, so that we use all data for training and validating. By statistically combining these model predictions, we can determine the more accurate evaluation metrics. This approach is known as [**cross-validation**][wcv]. \n",
    "\n",
    "There are multiple different cross-validation methods. The scikit-learn library provides the following [cross-validation iterators][skcvi]:\n",
    "- `KFold` splits the data into k _folds_, trains on  $k - 1$ folds, and validates on the remaining fold.\n",
    "- `StratifiedKFold` similar to `KFold`, but preserves the relative ratio of labeled classes within each fold.\n",
    "- `GroupKFold` similar to `KFold`, but limits the testing data to only one group within each fold.\n",
    "- `LeaveOneOut` iteratively leaves one observation out to validate the model trained on the remaining data.\n",
    "- `LeavePOut` iteratively leaves $P$ observations out to validate the model trained on the remaining data.\n",
    "- `ShuffleSplit` generates a user defined number of train/validate data sets, by first randomly shuffling the data.\n",
    "\n",
    "These different cross-validation techniques are demonstrated in the following set of Code cells. First, we create a ten-element array to demonstrate how these different techniques generate training and validating data set. Note, in this case, we generate data with only one feature (a numerical value zero through nine, inclusive), but these results extend to multi-feature data sets. In addition, these cross-validation techniques are implemented as iterators, which enables them to be used in loops to create the training and testing data sets, that can subsequently be processed efficiently inside the body of the _for_ loop.\n",
    "\n",
    "-----\n",
    "[wcv]: https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "[skcvi]: http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# We create a ten element data array to demonstrate\n",
    "# cross-validation iterators\n",
    "data = np.arange(10)\n",
    "print(f'{data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### KFold\n",
    "\n",
    "One of the most popular cross-validation techniques is the k-fold cross-validation. This technique is implemented in the scikit-learn library in the [`KFold`][skkf] iterator. This technique generates $k$ samples by splitting the original data into training and testing samples. If there are $n$ data values, the testing samples will contain  $n/k$ values. This is demonstrated in the following Code cell, where we apply K-fold to a ten-element array. In this case, $k=5$, the original dataset is splitted into 5 parts, with each part having 2 elements. There are then 5 iterations. In each iteration, one part will be the testing set and the other 4 parts will be the training set. If you combine the testing sets from all 5 iterations, you'll get the complete dataset.\n",
    "\n",
    "-----\n",
    "[skkf]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\t\t\t  Test\n",
      "------------------------------\n",
      "[2 3 4 5 6 7 8 9]        [0 1]\n",
      "[0 1 4 5 6 7 8 9]        [2 3]\n",
      "[0 1 2 3 6 7 8 9]        [4 5]\n",
      "[0 1 2 3 4 5 8 9]        [6 7]\n",
      "[0 1 2 3 4 5 6 7]        [8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create cross-validation iterator\n",
    "kf = KFold(n_splits=5, random_state=23)\n",
    "\n",
    "# Compute and display results\n",
    "print('Train\\t\\t\\t  Test')\n",
    "print(30*'-')\n",
    "for train, test in kf.split(data):\n",
    "    print(f'{train}        {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Stratified KFold\n",
    "\n",
    "When the training data is unbalanced, we need to be careful when dividing the data into training and testing data sets, so that class balance is preserved in both training and testing. Otherwise, the resulting model will perform poorly in the testing process (or even worse, on new unseen data). In this case, we may employ stratified sampling, which attempts to preserve class balance in the training and testing data sets. The scikit-learn module provides several stratified cross-validation techniques including:\n",
    "- [`StratifiedKFold`][skskf]\n",
    "- [`StratifiedShuffleSplit`][sksss].\n",
    "\n",
    "You may ask one question: \"Isn't Stratified Kfold always preferred over Kfold? Even with balanced dataset, Stratified Kfold will just work as well as Kfold. Why do we ever need Kfold if we have Stratified Kfold?\"\n",
    "\n",
    "The reason is a bit subtle. When we train and evaluate a model, we don't want to introduce any new information other than the dataset itself. Stratified Kfold splits the dataset depending on the labels. This process assumes that the proportion of each class in the training dataset reflects that of the population. This assumption is a kind of new information. Since the dataset we have is most likely not the population data, we really don't know whether the class proportion in the available data is true or not. On the other hand, Kfold splits the dataset randomly so it doesn't introduce any new information to the dataset. So for a very unbalanced dataset, choose Stratified Kfold, otherwise choose Kfold.\n",
    "\n",
    "-----\n",
    "[skskf]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "[sksss]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Leave One Out\n",
    "\n",
    "\n",
    "The simplest cross-validation technique to understand is the leave-one-out technique, which is implemented in the scikit-learn library by the [`LeaveOneOut`][skloo] iterator. This technique iteratively holds out one data value from the input data set out for testing, while the others are used for training. Thus, if we have ten data values, we will end up with ten samples, with each having nine values for training and one for testing. \n",
    "\n",
    "The following Code cell demonstrates this cross-validation technique, where we divide the original ten-element array into ten samples, where one value is held out for testing and nine are used for training.\n",
    "\n",
    "-----\n",
    "\n",
    "[skloo]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\t\t\t  Test\n",
      "------------------------------\n",
      "[1 2 3 4 5 6 7 8 9]        [0]\n",
      "[0 2 3 4 5 6 7 8 9]        [1]\n",
      "[0 1 3 4 5 6 7 8 9]        [2]\n",
      "[0 1 2 4 5 6 7 8 9]        [3]\n",
      "[0 1 2 3 5 6 7 8 9]        [4]\n",
      "[0 1 2 3 4 6 7 8 9]        [5]\n",
      "[0 1 2 3 4 5 7 8 9]        [6]\n",
      "[0 1 2 3 4 5 6 8 9]        [7]\n",
      "[0 1 2 3 4 5 6 7 9]        [8]\n",
      "[0 1 2 3 4 5 6 7 8]        [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Create cross-validation iterator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Compute and display results\n",
    "print('Train\\t\\t\\t  Test')\n",
    "print(30*'-')\n",
    "for train, test in loo.split(data):\n",
    "    print(f'{train}        {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Leave P Out\n",
    "\n",
    "We can extend the leave-one-out cross-validation technique to leave multiple items out. Note, however, that this can generate a very large number of splits. This technique is implemented in the scikit-learn library in the [`LeavePOut`][sklpo] iterator. Given $n$ data points, selecting $p$ items to leave out is a combinatorial problem:\n",
    "\n",
    "$$\n",
    "{n \\choose p}= \\frac{n!}{p! (n - p)!}\n",
    "$$\n",
    "\n",
    "For example, when n = 10, and p = 2, we have forty-five different splits that can be created. This cross-validation technique is demonstrated in the following Code cell, where to limit the output we select splits from only the first half of our data array. This results in only ten splits, which will more easily fit in this notebook. \n",
    "\n",
    "Notice how the training data clearly follow the combinatorial process: the first value is selected, and then the second one iterates through the remaining combinations. Next, the first value is incremented, and the process continues until no new, unique splits can be created.\n",
    "\n",
    "-----\n",
    "[sklpo]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\t\tTest\n",
      "--------------------\n",
      "[2 3 4]        [0 1]\n",
      "[1 3 4]        [0 2]\n",
      "[1 2 4]        [0 3]\n",
      "[1 2 3]        [0 4]\n",
      "[0 3 4]        [1 2]\n",
      "[0 2 4]        [1 3]\n",
      "[0 2 3]        [1 4]\n",
      "[0 1 4]        [2 3]\n",
      "[0 1 3]        [2 4]\n",
      "[0 1 2]        [3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "# Create cross-validation iterator\n",
    "lpo = LeavePOut(p=2)\n",
    "\n",
    "# Compute and display results\n",
    "print('Train\\t\\tTest')\n",
    "print(20*'-')\n",
    "\n",
    "# We only use first five values in our data array to limit output\n",
    "for train, test in lpo.split(data[:5]):\n",
    "    print(f'{train}        {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Shuffle Split\n",
    "\n",
    "Shuffle split is implemented in the scikit-learn library by the [`ShuffleSplit`][skss] iterator. This form of cross-validation first randomly shuffles the data, and then splits the data into the training and testing samples. This provides an extra degree of randomness, since data can appear in a training or testing set more times than with the other cross-validation techniques. This is demonstrated in the following Code cell, where we create ten samples with 80% of the data used for training from our original numerical sample. If equally divided, each number should appear in the test data twice, but the output indicates numbers can occur once, twice, and even three times.\n",
    "\n",
    "-----\n",
    "[skss]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain\t\tTest\n",
      "------------------------------\n",
      "[2 9 4 7 1 0 6 3]      [5 8]\n",
      "[8 2 1 4 5 9 6 3]      [0 7]\n",
      "[4 3 6 2 1 9 5 0]      [7 8]\n",
      "[2 5 3 8 9 1 4 7]      [0 6]\n",
      "[0 7 4 8 2 1 6 3]      [9 5]\n",
      "[4 2 5 0 8 7 9 6]      [1 3]\n",
      "[1 5 9 7 2 6 0 3]      [4 8]\n",
      "[0 8 4 5 3 2 9 7]      [6 1]\n",
      "[5 2 8 6 1 3 4 0]      [9 7]\n",
      "[6 4 3 0 2 1 7 8]      [5 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Create cross-validation iterator\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.2, random_state=23)\n",
    "\n",
    "# Display results\n",
    "print('\\tTrain\\t\\tTest')\n",
    "print(30*'-')\n",
    "for train, test in ss.split(data):\n",
    "    print(f'{train}      {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Group KFold\n",
    "\n",
    "In some cases, data are naturally grouped. For example, we might have data that have a natural grouping, such as data collected from different runs using the same equipment, or from runs that were done by different laboratories. Likewise, if the data are not independent, we can look for a natural grouping that would enable cross-validation to be utilized. In these cases, we need a different cross-validation technique that maintains the group structure so that groups do not span training and testing data. These techniques are known as group-wise cross-validators. The scikit-learn library provides group-wise versions of the main cross-validation techniques, including:\n",
    "- [`GroupKFold`][skgkf]\n",
    "- [`LeaveOneGroupOut`][skloo]\n",
    "- [`LeavePGroupsOut`][sklpo]\n",
    "- [`GroupShuffleSplit`][skgss]\n",
    "\n",
    "-----\n",
    "[skgkf]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html\n",
    "[skloo]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html\n",
    "[sklpo]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html\n",
    "[skgss]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cells, we demonstrated different cross-validation techniques. Now that you have run the previous cells, try making changes to the notebook and see if you can predict the results.\n",
    "\n",
    "1. Change the original data array to contain only odd integers between 1 and 21. How do the folds in the `KFold` cross-validation technique change?\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model with Cross-Validation\n",
    "\n",
    "We can now compute cross validation score for a given model. The easiest way to accomplish this is to use the [`cross_val_score`][skcvs] function in the scikit-learn module, which applies an estimator with a cross-validation technique to a training data set. This function will compute and return an array of scores for each fold in the cross-validation. The scores are computed using the default score method for the provided estimator, such as `accuracy`, but different metrics can be supplied via the `scoring` hyperparameter.\n",
    "\n",
    "In the following code, we apply `cross_val_score` function on the decision tree classifier created above. The training dataset is the adult income data. Since the data is unbalanced, we will choose StratifiedKFold with 10 folds as cross validation iterator. The number of folds(k) is determined by the number of instances in the dataset. The value for k is chosen such that each train/test group of data samples is large enough to be statistically representative of the broader dataset. 5 and 10 are commonly accepted k values. Adult income data has 4000 instances, so we choose 10 folds. For a smaller dataset, like the Iris or the Tips dataset, we may choose 5 folds.\n",
    "\n",
    "The `cross_val_score` function returns an array of scores, one for each iteration. We take the mean of the scores and print it out as the accuracy score of our model. The accuracy now is 80.4% which is between the two scores we got from train-test split approach. It's considered as the more reliable accuracy score.\n",
    "\n",
    "-----\n",
    "[skcvs]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score from Cross Validation: 80.4%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=23)\n",
    "score = cross_val_score(adult_model, features, label, cv=skf)\n",
    "\n",
    "print(f'Accuracy Score from Cross Validation: {np.mean(score)*100:4.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cell, we used StratifiedKFold with 10 fold in `cross_val_score`. Try to make the following changes and see if what you get.\n",
    "\n",
    "1. Change the number of splits, i.e., 5 folds, in StratifiedKFold.\n",
    "2. Use `KFold` instead of `StratifiedKFold`.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Scorer\n",
    "\n",
    "`cross_val_score` only returns one kind of score which by default is accuracy score for classification and $R^2$ score for regression. You may set `scoring` argument to get other cross validation scores. The following Code cell demonstrates how to return an accuracy score(default), a precision score of positive class, a recall score of positive class, and area under curve from `cross_val_score`. Check out [sklearn.metrics module](#https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score from Cross Validation: 80.4%\n",
      "Positive Precision Rate from Cross Validation: 56.9%\n",
      "Positive Recall Rate from Cross Validation: 59.6%\n",
      "Area Under Curve from Cross Validation: 73.1%\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, random_state=23)\n",
    "\n",
    "#accuracy\n",
    "score = cross_val_score(adult_model, features, label, cv=skf)\n",
    "#positive precision\n",
    "precision_score = cross_val_score(adult_model, features, label, cv=skf, scoring='precision')\n",
    "#positive recall\n",
    "recall_score = cross_val_score(adult_model, features, label, cv=skf, scoring='recall')\n",
    "#auc\n",
    "auc_score = cross_val_score(adult_model, features, label, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print(f'Accuracy Score from Cross Validation: {np.mean(score)*100:4.1f}%')\n",
    "print(f'Positive Precision Rate from Cross Validation: {np.mean(precision_score)*100:4.1f}%')\n",
    "print(f'Positive Recall Rate from Cross Validation: {np.mean(recall_score)*100:4.1f}%')\n",
    "print(f'Area Under Curve from Cross Validation: {np.mean(auc_score)*100:4.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancillary information\n",
    "\n",
    "The following links are to additional documentation that you might find helpful in learning this material. Reading these web-accessible documents is completely optional.\n",
    "\n",
    "1. [A Gentle Introduction to k-fold Cross-Validation][1]\n",
    "\n",
    "-----\n",
    "\n",
    "[1]: https://machinelearningmastery.com/k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2019: Gies College of Business at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Model Selection\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the growth of machine learning, there is an evergrowing list of algorithms that can be used to model data. In previous notebooks, we have introduced many of the most popular machine learning algorithms, including linear and logistic regression, support vector machine, decision trees, k-nearest neighbors, and ensemble techniques like random forest. In addition, these algorithms all have their own set of hyperparameters whose values, for optimal performance, must be carefully selected. \n",
    "\n",
    "As a result, selecting the best model and associated set of hyperparameters can be a daunting task. In this notebook, we explore the topic of [**Model Selection**][skms] by first manually evaluating one hyperparameter for one machine learning algorithm on a specific data set. This will introduce the basic concepts required to perform model selection, before we move into more automated techniques with help of cross-validation which is introduced in the previous lesson. Following this, we will look at grid searches to find the best combinations of multiple hyperparameters. Finally, we will look at additional model selection techniques such as random hyperparameter searches.\n",
    "\n",
    "-----\n",
    "[skms]: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Model Selection](#Model-Selection)\n",
    "\n",
    "[Grid Search](#Grid-Search)\n",
    "\n",
    "- [Multi-Dimensional Grid Search](#Multi-Dimensional-Grid-Search)\n",
    "\n",
    "[Randomized Grid Search](#Randomized-Grid-Search)\n",
    "\n",
    "-----\n",
    "\n",
    "Before proceeding with the rest of this Notebook, we first have our standard notebook setup code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set global fiugure properties\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({'axes.titlesize' : 20,\n",
    "                     'axes.labelsize' : 18,\n",
    "                     'legend.fontsize': 16})\n",
    "\n",
    "# Set default seaborn plotting style\n",
    "sns.set_style('white')\n",
    "\n",
    "# Some cells take a while to run, so we will time them\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "Formally, model selection is the task of choosing the best machine learning model for a given data set. Thus, to get started, we first need a data set to which we can apply machine learning algorithms. For this purpose we will use the adult income data set. The first Code cell below load and prepare the dataset.\n",
    "\n",
    "For the purpose of simplicity, we will use only one machine learning algorithm in this notebook, and focus on finding the best hyperparameters for this one algorithm on these data. The machine learning algorithm we will use is k-nearest neighbors classification. KNN works better with normalized data, but for simplicity, we will bypass this step.\n",
    "\n",
    "In this simple example, we will only evaluate one potential hyperparameter, `n_neighbors` for this one algorithm. On a real-world problem, however, we likely would evaluate multiple algorithms, each with various hyperparameter combinations in order to determine the best model. \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3846</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1658</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3415</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3678</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  EducationLevel  MaritalStatus  Occupation  Relationship  \\\n",
       "3846   22              10              4          10             4   \n",
       "848    55              14              2           4             0   \n",
       "1658   34              12              2           1             0   \n",
       "3415   53               9              0           1             1   \n",
       "3678   31               9              2           1             2   \n",
       "\n",
       "      CapitalGain  HoursPerWeek  Label  \n",
       "3846            0            20      0  \n",
       "848             0            60      1  \n",
       "1658            0            28      0  \n",
       "3415            0            40      0  \n",
       "3678            0            35      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read CSV data\n",
    "adult_data = pd.read_csv('data/adult_income.csv')\n",
    "\n",
    "# Create label column, one for >50K, zero otherwise.\n",
    "adult_data['Label'] = adult_data['Salary'].map(lambda x : 1 if '>50K' in x else 0)\n",
    "\n",
    "# Generate categorical features(with string values)\n",
    "categorical_features = adult_data[['Workclass', 'Education', 'MaritalStatus', \n",
    "               'Occupation', 'Relationship', 'Race', 'Sex', 'NativeCountry']]\n",
    "\n",
    "#encode categorical features\n",
    "categorical_features = categorical_features.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Extract numerical features\n",
    "numerical_features = adult_data[['Age', 'FNLWGT', 'EducationLevel', 'CapitalGain', 'CapitalLoss', 'HoursPerWeek']]\n",
    "\n",
    "all_features = pd.concat([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "features = all_features[['Age', 'EducationLevel', 'MaritalStatus', 'Occupation', \n",
    "                         'Relationship', 'CapitalGain', 'HoursPerWeek']]\n",
    "\n",
    "label = adult_data['Label']\n",
    "\n",
    "#display sample data(for display purpose only)\n",
    "pd.concat([features, label], axis=1).sample(5, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Hold Unused Test Set\n",
    "\n",
    "The next step is to split the dataset to train and test set. We will only use the train set for model selection. The reason is that the test set is used to evaluate the final trained model and it should never be used to change the model(hyperparameters). The whole process is:\n",
    "1. Split data to train and test set.\n",
    "2. Select model hyperparameter values with train set only.\n",
    "3. Train the model with optimum hyperparameter values on train set.\n",
    "4. Evaluate trained model with test set.\n",
    "\n",
    "In this lesson, we will only do the first two steps to focus on model selection. \n",
    "\n",
    "In the next Code cell, we split the dataset to train and test set. Then in the rest of this notebook, we will use the train set to select model hyperparameters.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "d_train, d_test, l_train, l_test = train_test_split(features, label, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Select Model with Cross Validation\n",
    "\n",
    "The next step is to create a cross-validation iterator that will be applied to the training data to evaluate the model hyperparameters. In this case, we employ a stratified k-fold cross-validation technique to once again maintain class balance. We also specify 10 folds (via the `n_splits` parameter), which will produce 10 unique training and validation data sets for each hyperparameter. \n",
    "\n",
    "We create an array of nine `n_neighbors` values between 1 to 107 for the model selection process. We pick these values arbitrarily just for demonstration purpose. You can define an array with all integers under 100, but the whole process will take a lot more time to run.\n",
    "\n",
    "We then iterate through each value in the array of hyperparameter values, compute and display the cross-validation scores for each value. Finally, we display the total time taken for this specific cross-validation.\n",
    "\n",
    "For only nine different values of n_neighbors, the code takes almost 2 seconds to run as shown below.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors=1, score=79.7%\n",
      "neighbors=3, score=81.5%\n",
      "neighbors=5, score=82.5%\n",
      "neighbors=11, score=82.8%\n",
      "neighbors=17, score=82.7%\n",
      "neighbors=23, score=82.9%\n",
      "neighbors=31, score=83.1%\n",
      "neighbors=53, score=82.9%\n",
      "neighbors=107, score=82.3%\n",
      "Compute time = 1.91 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "start = time()\n",
    "skf = StratifiedKFold(n_splits=10, random_state=23)\n",
    "\n",
    "neighbors = [1, 3, 5, 11, 17, 23, 31, 53, 107]\n",
    "for n in neighbors:\n",
    "    knc = KNeighborsClassifier(n_neighbors=n)\n",
    "    score = cross_val_score(knc, d_train, l_train, cv=skf)\n",
    "    print(f'neighbors={n}, score={np.mean(score)*100:4.1f}%')\n",
    "# Display compute time\n",
    "print(f'Compute time = {time() - start:4.2f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "From the above code, we find out that for all the number of neighbors tested, 31 gives the best accuracy score. Thus 31 is the best value for KNN hyperparameter `n_neighbors`. Keep two things in mind, however, first, this is only the best value among the n_neighbors values we tested, and secondly, this is based on the accuracy score only. You may change to other scoring function like `'precision'`, `'recall`' or `'roc_auc'` to get completely different results.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cells, we applied cross-validation using a KNN classification estimator to the adult income data set to determine the best `n_neighbors` hyperparameter. Now that you have seen this technique work, try making the following changes and see if you can explain the results.\n",
    "\n",
    "1. Set `cross_val_score` argument `scoring` to `roc_auc`.\n",
    "2. Change the algorithm to use a random forest classifier, and vary the hyperparameters like `n_estimators` or `max_features`.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "Many machine learning algorithms have hyperparameters that can be adjusted to tune the performance of the algorithm on a particular data set, for example, the `n_neighbors` parameter in KNN. While in some cases there is a theoretical justification for a particular parameter value when applied to a specific data set, in many cases, we must determine the parameter values programmatically. With multiple parameters, however, this process can quickly become tedious.\n",
    "\n",
    "Rather than repeatedly changing parameter values and computing the resulting model scores, a better approach is to employ a grid search approach. In a grid search, one defines a grid of parameter values, applies the model over all possible parameter value combinations in the grid, and identifies the set of parameters that produces the best model performance score. The scikit-learn library provides a [`GridSearchCV`][skgs] object that performs a grid search by using cross validation, which produces a model score at the end.\n",
    "\n",
    "In the following Code cell, we demonstrate using `GridSearchCV` to compute the best value for the `n_neighbors` parameter when running the KNN classifier on the adult income data.\n",
    "\n",
    "-----\n",
    "[skgs]: http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time = 2.71 seconds.\n",
      "\n",
      "Best n_neighbors=31.0000\n",
      "Best CV Score = 0.831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Start clock\n",
    "start = time()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=23)\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "# Create a dictionary of hyperparameters and values\n",
    "neighbors = [1, 3, 5, 11, 17, 23, 31, 53, 107]\n",
    "params = {'n_neighbors':neighbors}\n",
    "\n",
    "# Create grid search cross validator\n",
    "gse = GridSearchCV(estimator=knc, param_grid=params, cv=skf)\n",
    "\n",
    "# Fit estimator\n",
    "gse.fit(d_train, l_train)\n",
    "\n",
    "# Display time and best estimator results.\n",
    "print(f'Compute time = {time() - start:4.2f} seconds.\\n')\n",
    "\n",
    "print(f'Best n_neighbors={gse.best_estimator_.get_params()[\"n_neighbors\"]:5.4f}')\n",
    "print(f'Best CV Score = {gse.best_score_:4.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Multi-Dimensional Grid Search\n",
    "\n",
    "The previous example performed a grid search on one hyperparameter. This approach can be extended to multiple hyperparameters by constructing a dictionary that maps the hyperparameters to the hyperparameter values. In the following Code cell, we demonstrate this by first creating arrays of our hyperparameter values, for both the `n_neighbors` and `weights`. Next, we construct the grid of the two hyperparameters for the KNN algorithm by using an explicit dictionary. Then we perform stratified k-fold cross-validation using our KNN model. At the end of the Code cell, we compute and display the processing time, the best fit hyperparameters, and the best cross-validation score.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time = 3.99 seconds.\n",
      "\n",
      "Best n_neighbors=53.0000\n",
      "Best weights=distance\n",
      "Best CV Score = 0.841\n"
     ]
    }
   ],
   "source": [
    "# Start clock\n",
    "start = time()\n",
    "\n",
    "# Define individual parameter values\n",
    "# Equal-spaced intervals in log-space\n",
    "neighbors = [1, 3, 5, 11, 17, 23, 31, 53, 107]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "skf = StratifiedKFold(n_splits=10, random_state=23)\n",
    "\n",
    "\n",
    "# Create a dictionary of hyperparameters and values\n",
    "params = {'n_neighbors':neighbors, 'weights':weights}\n",
    "\n",
    "# Create Grid Search Cross validation iterator\n",
    "mgse = GridSearchCV(estimator=knc, param_grid=params, cv=skf)\n",
    "\n",
    "# Fit and display results of grid search\n",
    "mgse.fit(d_train, l_train)\n",
    "\n",
    "# Compute and display results\n",
    "print(f'Compute time = {time() - start:4.2f} seconds.\\n')\n",
    "\n",
    "mgbe = mgse.best_estimator_\n",
    "print(f'Best n_neighbors={mgbe.get_params()[\"n_neighbors\"]:5.4f}')\n",
    "print(f'Best weights={mgbe.get_params()[\"weights\"]}')\n",
    "print(f'Best CV Score = {mgse.best_score_:4.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Randomized Grid Search\n",
    "\n",
    "For a large number of hyperparameters, the number of possible combinations quickly becomes excessive. Since we must evaluate the model for each possible combination of parameters, model selection with standard grid selection can become computationally intractable. The code in previous Code cell takes over twenty seconds to run with only 3 parameters that have limited options. \n",
    "\n",
    "An alternative approach is to randomly select possible hyperparameter combinations from the supplied grid of values to identify good parameter combinations.\n",
    "\n",
    "In the following Code cell, we demonstrate a random grid search by using the [`RandomizedSearchCV`][skrgs] estimator. First, we pass in our KNN classifier, along with the parameter grid, and the number of parameter values to sample. As this last value increases, more parameter value combinations are sampled. These values are sampled randomly from a distribution of each parameter. If a list of values is provided (as we have done with previous grid searches), the values are randomly sampled from the list. Alternatively, a random distribution can be used. The requirement for these distributions is that they must contain an `rvs` method, which is provided by the random distributions in the `scipy.stats` module. \n",
    "\n",
    "We demonstrate the technique in the example below. In the code, instead of nine neighbor values, we use `range()` to create a range of integers from 0 to 50. If we use GridSearchCV, there will be 50*2=100 iterations of model training, which will take very long time to finish. With RandomizedSearchCV, we can set `n_iter` to 20, which means we only compute scores for twenty different parameter combinations. The twenty combinations are randomly picked from all combinations. With a lot more hyperparameter value options, the code takes about 5 seconds to run.\n",
    "\n",
    "In the second Code cell, we extract the best estimator and display the optimal parameters and associated score. Note that while not the guaranteed best score (and hyperparameter values), we achieve similar score as GridSearchCV. Thus, the random search cross-validation can be useful to get reasonable hyperparameter values much faster than with traditional techniques.\n",
    "\n",
    "-----\n",
    "\n",
    "[skrgs]: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time = 1.86 seconds for 20 parameter combinations\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Start clock\n",
    "start = time()\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "skf = StratifiedKFold(n_splits=10, random_state=23)\n",
    "\n",
    "neighbors = range(1, 51)\n",
    "weights = ['uniform', 'distance']\n",
    "# Create a dictionary of hyperparameters and values\n",
    "params = {'n_neighbors':neighbors, 'weights':weights}\n",
    "\n",
    "# Number of random parameter samples\n",
    "num_samples = 20\n",
    "\n",
    "# Run randomized search\n",
    "rscv = RandomizedSearchCV(knc, param_distributions=params, n_iter=num_samples, random_state=23)\n",
    "\n",
    "# Fit grid search estimator and display results\n",
    "rscv.fit(d_train, l_train)\n",
    "\n",
    "print(f'Compute time = {time() - start:4.2f} seconds', end='')\n",
    "print(f' for {num_samples} parameter combinations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors=36.0000\n",
      "Best weights=distance\n",
      "Best CV Score = 0.838\n"
     ]
    }
   ],
   "source": [
    "# Get best esimtator\n",
    "be = rscv.best_estimator_\n",
    "\n",
    "# Display parameter values\n",
    "print(f'Best n_neighbors={be.get_params()[\"n_neighbors\"]:5.4f}')\n",
    "print(f'Best weights={be.get_params()[\"weights\"]}')\n",
    "\n",
    "# Display best score\n",
    "print(f'Best CV Score = {rscv.best_score_:4.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Ancillary Information\n",
    "\n",
    "The following links are to additional documentation that you might find helpful in learning this material. Reading these web-accessible documents is completely optional.\n",
    "\n",
    "1. The scikit-learn library’s [introduction][1] to hyperparameter tuning\n",
    "1. A discussion on [grid search][2] for algorithmic tuning from the machine learning mastery website\n",
    "\n",
    "2. The Wikipedia article on [hyperparameters][3]\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "[1]: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "[2]: https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\n",
    "[3]: https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2019: Gies College of Business at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

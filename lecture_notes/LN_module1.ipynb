{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction Script\n",
    "Hello and welcome. This is the first module of the course. This course is about machine learning algorithms and more importantly, how to apply those algorithms on real world dataset with python scripts. This module provides the basis for the rest of the course by introducing the basic concepts behind machine learning algorithms. You will be introduced with the types of the machine learning algorithms you are going to learn. You will also learn the basic steps to apply machine learning algorithms with python scikit learn library. The steps are very simple and stardard for all algorithms. Before applying machine learning algorithms, however, we need to pre-process the data. You will learn 3 types of pre-process techniques.\n",
    "\n",
    "There are three lessons in this module, please watch the video of each lesson, and more importantly, go through the lesson notebooks carefully. The videos explain the concepts but the most effective way to learn python data analytics is through practicing. I encourage you to run the code in the notebooks, you may even play with the code, make modifications and rerun the code to see different result.\n",
    "\n",
    "Please note that this module serves as an introduction to machine learning algorithms. You are not required to understand the details of the algorithms that are demonstrated in the lesson notebooks. You will learn those algorithms in more detail in the future lessons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lesson 1: Introduction to Machine Learning\n",
    "- Artificial Intelligence, Machine Learning and Deep Learning\n",
    "- Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 1\n",
    "#### Artificial Intelligence, Machine Learning and Deep Learning\n",
    "<img src=\"https://www.mytectra.com/media/wysiwyg/Blog/deep-learning.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 1 Script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 2\n",
    "#### Machine Learning\n",
    "Tow main tasks in machine learning field:\n",
    "- #### Supervised Learning\n",
    "Ground truth is available. The algorithms are provided with true outputs for a give inputs.\n",
    " - Classificaiton\n",
    " - Regression\n",
    "- #### Unsupervised Learning\n",
    "No corresponding output. The algorithms identify patterns and features from the data directly.\n",
    " - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 2 Script\n",
    "There are two main tasks in machine learning field: supervised learning and unsupervised learning.\n",
    "\n",
    "In supervised learning, the model or the algorithm is provided with groud truth for given inputs. For example, fraudulent transaction detection can be implemented with a supervised learning model. The inputs are transaction details such as amount, time, location, machant etc. We can train a machine learning model with past transactions, for which we already know whehter they are valid or not. After the model is trained with past data, it can be used to evaluate new transactions at real time and predict whether they fraudulent or not.\n",
    "\n",
    "We are going to introduce two kinds of supervised learning in this course, classification and regression. Classification is used when output is discrete. Like the fraud detection, the output is either fraudulent or not fraudulent. Regression is used when the output is continous. Like predicting sales or profits based on market conditions. \n",
    "\n",
    "A common technique to evaluate the effectiveness of a supervised learning model is to devide past data to training and testing set. Train the model with training dataset, then apply the trained model on testing data and get predictions, get model accuracy by comparing the predictions with the true labels of the testing dataset.\n",
    "\n",
    "In unsupervised learning, corresponding output is not available. The model tries to identify patterns and features from the data directly. For example, unsupervised learning can be used to segment sustomers into different groups by their profiles and purchasing habits. This kind of customer segmentation can help merchants to better serve their customers or promote their products more effectively.\n",
    "\n",
    "We are going to introduce clustering for unsupervised learning in this course. Clustering is an algorithm that groups objects into groups such that objects in same group are more similar then that in other groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 3\n",
    "#### Machine Learning Algorithms in this Course\n",
    "- Classification\n",
    "- Regression\n",
    "- Text Analysis\n",
    "- Clustering\n",
    "- Time Sieres Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 3 Script\n",
    "In this course, we are going to learn these 5 types of machine learning algoritms. Classification and Regression are supervised learning algorithms. Clustering is unsupervised learning algorithm. \n",
    "\n",
    "Text analysis is actaully a special kind of classfication problem. We introduce it separately because unlike normal classifications, the training data of text analysis is a collection of texts, like customer reviews or newspaper articles. Machine learning models can only deal with numerical data. So we have to first manipulate the text dataset and convert it to numeric data, then apply classification algorithms.\n",
    "\n",
    "Time series analysis is another kind of special machine learning algorithm. It's called time series analysis because the data is indexed by time. Like daily stock price, hourly weather conditions etc. Time series analysis tries to find the trend over time, and predict future values based on previous information. We normally don't classify time series analysis as supervised or unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lesson 2: Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 1\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/1920px-CRISP-DM_Process_Diagram.png' width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 1 Script\n",
    "This lesson is about data pre-processing. To understand data pre-processing let's review the crisp-dm framework first. In the framework, the third step is data preparation, in which we clean up the data, handle missing values, merge various data sources together. After this step we will have a clean dataset that is ready to be applied on machine learning models. Data pre-processing is often misunderstood as part of data preparation. The fact is, data pre-processing is part of modeling because it depends on the machine learning model that is in use. Some data pre-processing techniques are for supervised learning, some are for both supervised and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 2\n",
    "\n",
    "#### Data Pre-processing Techniques\n",
    "\n",
    "- Categorical Variables Encoding\n",
    "- Dataset Splitting\n",
    "- Data Scaling and Standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 2 Script\n",
    "In this lesson, we will introduce three data pre-processing techniques.   \n",
    "Categorical Variable Encoding  \n",
    "Dataset Splitting, and  \n",
    "Data Scaling  \n",
    "\n",
    "Among them, dataset splitting is for supervised learning algorithms only. Other two are for both supervised and unsupervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 3\n",
    "#### Categorical Variables\n",
    "- **Nominal**: \n",
    "Categories have no numerical orders. ie. Gender.\n",
    "- **Ordinal**: \n",
    "Categories have numerical orders. ie. ranking in a race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 3 Script\n",
    "\n",
    "The first data pre-processing technique we introduce is categorical variable encoding. Categorical variables are very common in machine learning datasets. There are two types of categorical variables, nominal and ordinal. \n",
    "\n",
    "A nominal variable has no intrinsic order in its categories. For example, gender is a categorical variable because the two categories (male and female) have no intrinsic order. Some other nominal variable examples are day of week, country of origin, color of shirt, etc.\n",
    "\n",
    "An ordinal variable, on the other hand, has some sort of order. For example, ranking in a race, first place, second place and third place, there's intrinsic order in the categories. Some other ordinal variable examples are passenger class, shirt or shoe size etc.\n",
    "\n",
    "For different type of categorical variables and machine learning models, there are many different encoding techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 4\n",
    "#### Categorical Variable Encoding\n",
    "- **Label Encoding**: Encode categories to unique numeric values.\n",
    "- **One Hot Encoding**: Create a dummy variable with value 0 and 1 for each category value.\n",
    "<img src='https://i.imgur.com/mtimFxh.png' width=500>\n",
    "<img src='https://miro.medium.com/max/2736/0*T5jaa2othYfXZX9W.' width=500>\n",
    "- **Ordinal Encoding**: Encode categories to ordered numerica values. Small->0, Medium->1, Large->2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 4 Script\n",
    "We introduce 3 most common types of encoding techniques in this lesson.\n",
    "\n",
    "The simplest approach is label encoding, which converts each category into a unique numeric value. Normally, if there are n different categories, they will be mapped to numbers from 0 to n-1. For example, if there's a color variable with 3 categories, red, yellow and blue, label encoding will map the three colors to 0, 1 and 2. Label encoding is normally used on normaimal categorical features. The map between category value and numeric value is somewhat random. Normally, alphabetical order of category values is used to determine which numeric value a category is mapped to. In the color case, blue is normally mapped to 0, red is mapped to 1 and yellow is mapped to 2 due to alphabetical order of the three words.\n",
    "\n",
    "Label encoding is straightforward but it has an apparent problem. It may mislead machine learning algorithms with the numeric values since it introduces an order into the category values. Some machine learning algorithms are sensitive to categorical values, like linear regression. For this kind of algorithms, one hot encoding normally provides a better learning result. One hot encoding creates extra dummy variables for a categorical variable. One dummy variable is created for each cagtegory value. For example, for the color example, one hot encoding will create three dummy variables, namely red, yellow and blue, one for each color. A dummy variable only has value 0 or 1. For example, if a data point has color yellow, the values in the 3 dummy variables red, yellow and blue will be 0, 1 and 0. Each data point will have only one value 1 in the three dummy variables. With one hot encoding, we don't introduce extra information into the dataset.\n",
    "\n",
    "The disadvantage of one hot encoding is that it increases the dataset size, espeically when there are a lot of categorical variables with many different categories. Some machine learning algorithms don't rely on values of categorical variables. For those algoritms, like decision tree or random forest, label encoding is good enough. For some other algorithms, like linear regression, which is sensitive to the categorical values, one hot encoding normally provides better result.\n",
    "\n",
    "Another approach is ordinal encoding, which is used to encode ordinal categorical variables. With ordianl encoding, a category value is mapped to a perticular numeric value based on its charactoristic. For example, we can map small to 0, medium to 1 and large to 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 5\n",
    "#### Dataset Splitting\n",
    "- For supervised learning\n",
    "- Split dataset to training and testing set\n",
    "- Use the training set to train the model\n",
    "- Use the testing set to evaluate the model\n",
    "\n",
    "<img src='https://www.researchgate.net/profile/Brian_Mwandau/publication/325870973/figure/fig6/AS:639531594285060@1529487622235/Train-Test-Data-Split.png' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 5 Script\n",
    "The second data pre-processing technique is dataset splitting. This techinque is used for supervised learning only. We split the original dataset to two datasets, training and testing. We use the training data set to train the model, then apply the trained model on the inputs of testing dataset to get predictions, use the prediction and the true output of testing dataset to evaluation the accuracy of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 6\n",
    "#### Data Scaling\n",
    "- Standardizing: zero mean and one standard deviation\n",
    "- Normalization: scale to same range, ie 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 6 Script\n",
    "Many machine learning algorithms are sensitive to variations in the spread of features. For example, an algorithm might give more weight on features with a larger spread, even if this produces a sub-optimal result. To prevent this kind of problems, we scale the features.\n",
    "\n",
    "We introduce two types of scaling in this lesson, standardizing and normalization.\n",
    "\n",
    "Standardizing scales data to mean 0 and standard deviation 1. Use standardizing when the data is normally distributed.\n",
    "\n",
    "Normalization scales data to a particular range, normally from 0 to 1. Normalization doesn't work well when there're outliers in the dataset. Assume majority of the data is in range 1-100, and only a few data points are in million or billion range, if we normalize the data to 0 to 1 range, most datapoints are mapped to close to 0 due the the very large outliers. In this case, we could eliminate outliers before applying normalization, or use standardization.\n",
    "\n",
    "Scaling is not required for all machine learning algorithms. For example, for decsition tree or random forest, we don't need to scale the data. We will discuss scaling in more details in future lessons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lesson 3: Introduction to Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 1\n",
    "#### Modeling with Scikit-Learn\n",
    "- Pre-process data\n",
    "- Create Model\n",
    "- Train the model\n",
    "- Evaluate the model\n",
    "- Predict with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Slide 1 Script\n",
    "In this lesson, we demonstrate modeling with python scikit learn library. We use a python built-in dataset, iris dataset to demonstrate how to perform classification, regression and clustering. Classification and regression are supervised learning and clustering is unsupervised learning.\n",
    "\n",
    "Python scikit learn library has various machine learning algorithms. The best part is, all algorithms have same interface, which means we can follow same steps when applying different algorithms. The steps are:\n",
    "- first, Pre-process data\n",
    "- then Create Model\n",
    "- then Train the model\n",
    "- then Evaluate the model\n",
    "- finally Predict with the model\n",
    "\n",
    "For classification, we demonstrate K-nearest neighbors classifier; for regression, we demnonstrate decision tree regressor; for clustering, we demonstrate kmeans algorithm. Don't worry if you don't know anything about these algorithms because we will learn the algorithms in the following lessons. In this lesson, just understand the basic steps of applying scikit learn machine learning models and appreciate how simple they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 2\n",
    "\n",
    "- #### Open Notebook to Show Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide 2 Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Review Script\n",
    "\n",
    "In this lesson you learned some basic concept behind machine learning algorithms. In lesson 3 we demonstrate how to use python scikit learn library to do classification, regression and clustering. You are not required to understand the details of the algorithms demonstrated since you are going to learn them in the following lessons. You are required to understand the concept of data pre-processing, and be able to pre-process data with python scripts introduced in lesson 2.\n",
    "\n",
    "The first module's assignment is fairly straightforward. Just remember to work on the problems in order.\n",
    "\n",
    "Good luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 Assignment\n",
    "\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and Restart & Run all. \n",
    "2. Make sure that you save your work.\n",
    "3. Upload your notebook to Compass.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Yelp Review Data\n",
    "\n",
    "This assignment will use the Yelp review dataset. Before we attempt to build a model, we first prepare the data.\n",
    "\n",
    "The Yelp review dataset contains 1000 customer reviews of a group of restaurants. There are two columns in the dataset, column **stars**, which is the star rating, and column __text__, which is the review text. The dataset only contains 1-star and 5-star reviews. There are 500 1-star reviews and 500 5-star reviews.\n",
    "\n",
    "Please run the next code cell before proceeding to Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of Reviews by Star Rating:\n",
      "5    500\n",
      "1    500\n",
      "Name: stars, dtype: int64\n",
      "\n",
      "Sample Review(5 stars):\n",
      "I love love LOVE this place. My boss (who is into healthy eating) recommended this place. I went over with some highly skeptical friends and one dinner was enough to convert them into believers! The food here is so good! We had the Shrimp dumplings and the Onion tart as starters. We ordered the Shirataki noodles and street tacos as entrees. So also ordered the Kale-aid. All of the dishes were yummy. \n",
      "I have gone back many times since then and have never been disappointed! I have gone after yoga to get some Kale salad or the chicken chopped salad. I always have to get the Kale aid. \n",
      "Once, a guy at the next table, uprooted a whole plant by mistake (on the patio) and was highly embarrassed as was his date! Ever since, I have very careful not to throw my arms around as I can be quite clumsy sometimes! I do NOT want to be banned from my favorite place for my clumsiness! I don't think I can live without True Food!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Dataset Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>Celebrated my anniversary here. Everything was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1</td>\n",
       "      <td>I had such high expectaions after reading revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stars                                               text\n",
       "37       5  Celebrated my anniversary here. Everything was...\n",
       "726      1  I had such high expectaions after reading revi..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Load yelp review dataset\n",
    "df = pd.read_csv('yelp_reviews.csv')\n",
    "print(f'Counts of Reviews by Star Rating:\\n{df.stars.value_counts()}\\n')\n",
    "print(f'Sample Review({df.stars[0]} stars):\\n{df.text[0]}')\n",
    "print('-'*80)\n",
    "print('\\nDataset Sample:')\n",
    "\n",
    "df.sample(2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Problem 1: Prepare Data for Sentiment Analysis\n",
    "Create label and split text data set to training and testing set.\n",
    "\n",
    "For this problem you will use `df` created above.\n",
    "\n",
    "To solve this problem do the following:\n",
    "1. Import needed modules.\n",
    "2. Create `label` column in DataFrame `df`. Set label to 1(positive) if stars is 5, and 0 (negative) otherwise. Display ramdom 5 rows of `df` to verify the column is created correctly.\n",
    "3. Create variable **label**  which is the `label` column in `df`, and variable __data__ which is the `text` column in `df`. \n",
    "4. Split `data` and `label` to training and testing using `train_test_split`.\n",
    " - Set test_size to 0.4.\n",
    " - Assign return values to **d_train, d_test, l_train, l_test**.\n",
    "\n",
    "After this problem, there are four new variable, **d_train, d_test, l_train** and  __l_test__ defined.\n",
    "\n",
    "Feel free to add extra code cells if needed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>1</td>\n",
       "      <td>What was Dunkin Donuts thinking when they took...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>1</td>\n",
       "      <td>I guess this is an east coast/midwest thing be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1</td>\n",
       "      <td>After landing in PHX but before embarking on a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>1</td>\n",
       "      <td>I am totally baffled why this place gets such ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "      <td>I was looking into gyms around the area. Upon ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stars                                               text  label\n",
       "757      1  What was Dunkin Donuts thinking when they took...      0\n",
       "606      1  I guess this is an east coast/midwest thing be...      0\n",
       "509      1  After landing in PHX but before embarking on a...      0\n",
       "723      1  I am totally baffled why this place gets such ...      0\n",
       "561      1  I was looking into gyms around the area. Upon ...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer\n",
    "df['label'] = 0\n",
    "df.loc[df.stars==5, 'label'] = 1\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label = df.label\n",
    "data = df.text\n",
    "\n",
    "d_train, d_test, l_train, l_test = train_test_split(data, label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Problem 2: Train a LogisticRegression Model\n",
    "\n",
    "For this problem, use d_train, l_train, d_test and l_test created in problem 1.\n",
    "\n",
    "Your task for this problem is to build and train a `LogisticRegression` estimator to make predictions on the Yelp review dataset. \n",
    "\n",
    "To solve this problem do the following:\n",
    "1. Import needed modules.\n",
    "2. Create a `TfidfVectorizer` object **tf_cv**, set `stop_words` to 'english'.\n",
    "3. Fit the `TfidfVectorizer` objec with d_train.\n",
    "4. Transform d_train and d_test with the `TfidfVectorizer` object to get **train_dtm** and __test_dtm__.\n",
    "5. Create a `LogisticRegression` estimator **lr_model**. Set `C` to `1E6`(1000000). Accept default values for all other hyperparameters.\n",
    "6. Fit the `LogisticRegression` estimator using train_dtm and l_train.\n",
    "7. Calculate the mean accuracy score of **lr_model**.\n",
    "    - Apply lr_model `predict` function on test_dtm to get predicted label, assign it to variable **l_pred**.\n",
    "    - Use `accuracy_score` function in `metrics` module on l_test and l_pred to calculate the mean accuracy score.\n",
    "8. Display the mean accuracy score.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "tf_cv = TfidfVectorizer(stop_words='english')\n",
    "train_dtm = tf_cv.fit_transform(d_train)\n",
    "test_dtm = tf_cv.transform(d_test)\n",
    "\n",
    "# Fit model, predict, and calculate accuracy score\n",
    "lr_model = LogisticRegression(C=1E6)\n",
    "lr_model = lr_model.fit(train_dtm, l_train)\n",
    "l_pred = lr_model.predict(test_dtm)\n",
    "mas_score_lr = metrics.accuracy_score(l_test, l_pred)\n",
    "mas_score_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Problem 3: Get Top 10 Words in Positive Reviews\n",
    "\n",
    "Get to 10 words in positive reviews.\n",
    "\n",
    "This problem will use **lr_model** and __tf_cv__ created in problem 2.\n",
    "\n",
    "To solve this problem do the following:\n",
    "1. Import needed modules.\n",
    "2. Use tf_cv `get_feature_names` function to get all tokens (words) from the TfidfVectorizer object. Convert the token list to numpy array and assign the numpy array to variable **all_words**.\n",
    "3. Sort **lr_model** `coef_` attribute with `numpy argsort` function and get the last 10 items' index and assign to **top_words_index**.\n",
    "4. Get top 10 words using all_words and top_words_index and assign top 10 words list to **top10_positive_words**.\n",
    "5. Reverse top10_positive_words.\n",
    "6. Display the top 10 words in positive reviews.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'best',\n",
       " 'amazing',\n",
       " 'love',\n",
       " 'awesome',\n",
       " 'friendly',\n",
       " 'good',\n",
       " 'favorite',\n",
       " 'delicious',\n",
       " 'stop']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer\n",
    "import numpy as np\n",
    "\n",
    "all_words = np.array(tf_cv.get_feature_names())\n",
    "top_words_index = np.argsort(lr_model.coef_[0])[-10:]\n",
    "top10_positive_words = [word for word in all_words[top_words_index]]\n",
    "top10_positive_words.reverse()\n",
    "top10_positive_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Problem 4: Get Top 10 Words in Negative Reviews\n",
    "\n",
    "Get top 10 words in negative reviews.\n",
    "\n",
    "This problem will use **lr_model, all_words, train_dtm, l_train** created above.\n",
    "\n",
    "To solve this problem do the following:\n",
    "1. Reverse **l_train** values, change 0 to 1 and 1 to 0 and create another training label **l_train_2**.\n",
    "2. Fit the **lr_model** with __train_dtm__ and **l_train_2**.\n",
    "3. Get top 10 words from **lr_model**.\n",
    "    - Sort **lr_model** `coef_` attribute and get the last 10 items' index and assign to **top_words_index**.\n",
    "    - Get top 10 words using **all_words** created in problem 3 and top_words_index and assign top 10 words list to **top10_negative_words**.\n",
    "    - Reverse top10_negative_words.\n",
    "4. Display the top 10 words in negative reviews.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'horrible',\n",
       " 'worst',\n",
       " 'don',\n",
       " 'told',\n",
       " 'poor',\n",
       " 'rude',\n",
       " 'asked',\n",
       " 'ordered',\n",
       " 'didn']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer\n",
    "l_train_2 = [0 if y==1 else 1 for y in l_train]\n",
    "lr_model = lr_model.fit(train_dtm, l_train_2)\n",
    "\n",
    "top_words_index = np.argsort(lr_model.coef_[0])[-10:]\n",
    "top10_negative_words = [word for word in all_words[top_words_index]]\n",
    "top10_negative_words.reverse()\n",
    "\n",
    "top10_negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Problem 5: Use Custom Stop Words\n",
    "\n",
    "Add two words, \"went\" and \"company\", to English stop words and train a LogisticRegression model. The two words are rather neutral, we hope to get a better classification result with this change.\n",
    "\n",
    "This problem will use **d_train, d_test, l_train, l_test** created in problem 1.\n",
    "\n",
    "To solve this problem do the following:\n",
    "1. Import needed modules.\n",
    "    - If needed, install nltk package in a terminal with command `conda install nltk`.\n",
    "2. Get all English stop words from `stopwords` in `nltk.corpus` module, assign stop words list to variable **stop_words**.\n",
    "3. Add two words \"went\" and \"company\" into stop_words.\n",
    "4. Create a `TfidfVectorizer` object **tf_cv_2**, set `stop_words` to stop_words created in step 2.\n",
    "5. Fit the tf_cv_2 with d_train.\n",
    "6. Transform d_train and d_test with tf_cv_2 to get **train_dtm_2** and __test_dtm_2__.\n",
    "7. Create a `LogisticRegression` estimator **lr_model_2**. Set `C` to `1E6`(1000000). Accept default values for all other hyperparameters.\n",
    "8. Fit lr_model_2 using train_dtm_2 and l_train.\n",
    "9. Calculate the mean accuray score.\n",
    "    - Apply lr_model_2 `predict` function on test_dtm_2 to get predicted label, assign it to variable l_pred.\n",
    "    - Use `accuracy_score` function in `metrics` module on l_test and l_pred to calculate the mean accuracy score.\n",
    "10. Display the mean accuracy score.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "#add to stop words\n",
    "stop_words.extend(['went', 'company'])\n",
    "tf_cv_2 = TfidfVectorizer(stop_words=stop_words)\n",
    "train_dtm_2 = tf_cv_2.fit_transform(d_train)\n",
    "test_dtm_2 = tf_cv_2.transform(d_test)\n",
    "\n",
    "# Fit model, predict, and calculate accuracy score\n",
    "lr_model_2 = LogisticRegression(C=1E6)\n",
    "lr_model_2 = lr_model_2.fit(train_dtm_2, l_train)\n",
    "l_pred = lr_model_2.predict(test_dtm_2)\n",
    "mas_score_lr_2 = metrics.accuracy_score(l_test, l_pred)\n",
    "mas_score_lr_2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

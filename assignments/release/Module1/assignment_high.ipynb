{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a09eab40a4551c19daae51a40392817a",
     "grade": false,
     "grade_id": "cell-5fb9ace54ac8eb99",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Module 1 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Run the first code cell to import modules needed by this assignment before proceeding to problems.\n",
    "2. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "3. Each problem has an autograder cell below the answer cell. Run the autograder cell to check your answer. If there's anything wrong in your answer, the autograder cell will display error messages.\n",
    "4. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and Restart & Run all. If the notebook runs through the last code cell without error message, you've answered all problems correctly.\n",
    "5. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9c2b01117da89e89ac2e8f8fa53dfba5",
     "grade": false,
     "grade_id": "cell-b2cd1eba642080da",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Run Me First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "91e242e26761e5c93c7d999a6b4d0ec1",
     "grade": false,
     "grade_id": "cell-88dd2a72c7ccd97d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "66427a87be8335f1498e661364edaab4",
     "grade": false,
     "grade_id": "cell-12171359a60b47c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 1: Read in a dataset\n",
    "\n",
    "For this problem you will read in a dataset using pandas. In the cell below, the function *read_data* has parameter \"file_path\" which contains a path to a dataset.\n",
    "- Use the *read_csv* function from pandas to read in the dataset from the file path.\n",
    "- Drop all rows with missing values from the dataframe\n",
    "- Return the dataframe\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ee65d51e6ab2777245792f4d22de6e2e",
     "grade": false,
     "grade_id": "p1-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    '''\n",
    "    Reads in a dataset using pandas.\n",
    "    Drop all rows with missing values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : string containing path to a file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe with data read in from the file path\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e0246d1caa5a2c476e4657020e46cc26",
     "grade": true,
     "grade_id": "p1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mpg = read_data('data/mpg.csv')\n",
    "assert_equal(type(mpg), pd.core.frame.DataFrame, msg=\"Your function does't return a dataframe\")\n",
    "assert_equal(len(mpg), 392, msg=\"The dataset should have 392 rows. Your solution has %s\"%len(mpg))\n",
    "\n",
    "print(\"2 random rows of the dataset mpg:\")\n",
    "mpg.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a1755d00d9f78b076c371a00ba228a9",
     "grade": false,
     "grade_id": "cell-b123c07d7cb52a7a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 2: Encode \"origin\" column\n",
    "\n",
    "For this problem you will work on the DataFrame `mpg` created from problem 1.\n",
    "\n",
    "- One hot encode the categorical feature 'origin' using `get_dummies` in Pandas module. \n",
    "- Set the prefix of dummy columns to 'origin'.\n",
    "- Assign the resulting DataFrame to `mpg_onehot`.\n",
    "\n",
    "After this problem, DataFrame `mpg_onehot` should have three dummy features, `origin_europe`, `origin_japan` and `origin_usa` in addition to columns in DataFrame mpg(excluding `origin`).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0c5eb90b92046010acff56e3c582249c",
     "grade": false,
     "grade_id": "p2-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9ee6338965f03816af4c0576032ed653",
     "grade": true,
     "grade_id": "p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_true('origin_europe' in mpg_onehot.columns, msg=\"mpg doesn't have 'origin_europe' column\")\n",
    "assert_true('origin_japan' in mpg_onehot.columns, msg=\"mpg doesn't have 'origin_japan' column\")\n",
    "assert_true('origin_usa' in mpg_onehot.columns, msg=\"mpg doesn't have 'origin_usa' column\")\n",
    "mpg_onehot.sample(5, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6aec984213666ed34fd61e4020a49332",
     "grade": false,
     "grade_id": "cell-0bd8ccf5e00ce321",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 3: Define and split independent and dependent variables\n",
    "\n",
    "For this problem you will work on the DataFrame `mpg_onehot` created from problem 2.\n",
    "\n",
    "To complete this process, do the following:\n",
    "\n",
    "- Choose column 'mpg' in DataFrame `mpg_onehot` as dependent variable, set it to variable **y**  \n",
    "- Choose columns 'displacement', 'horsepower', 'acceleration' in DataFrame `mpg_onehot` as independent variable, set it to variable **x**  \n",
    "- Split dependent and independent variable to training and testing set\n",
    "- Name the training and testing independent variable to x_train and x_test\n",
    "- Name the training and testing dependent variable to y_train and y_test\n",
    "- The test_size argument in train_test_split should be set to 0.4.\n",
    "- The random_state argument in train_test_split should be set to 23.\n",
    "\n",
    "After this problem, there are 6 new variables defined, **x, y, x_train, x_test, y_train, y_test**.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "05b74779d38dad50da192a9ece0a2cbb",
     "grade": false,
     "grade_id": "p3-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b950f08c3d39f0902f8f380b6d57f80",
     "grade": true,
     "grade_id": "p3-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(x), pd.core.frame.DataFrame, msg=\"x should be a DataFrame\")\n",
    "assert_equal(type(y), pd.core.frame.Series, msg=\"x should be a Series\")\n",
    "assert_equal(len(x.columns), 3, msg=\"x should have 3 columns\")\n",
    "assert_true('displacement' in x.columns, msg=\"origin_usa is not in the independent variable\")\n",
    "assert_equal(y[0], 18, msg=\"dependent variable values are not right\")\n",
    "assert_equal(x_train.shape, (235, 3), msg=\"Independent training dataset size is not correct\")\n",
    "assert_equal(x_test.shape, (157, 3), msg=\"Independent testing dataset size is not correct\")\n",
    "x_train.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "67f57492b25cec33286e2acf3dbb61c3",
     "grade": false,
     "grade_id": "cell-a8e599edbe9c6fe0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "-----\n",
    "\n",
    "# Problem 4: Standardize dataset\n",
    "\n",
    "This problem works on the variables **x_train** and __x_test__ created in problem 3.\n",
    "\n",
    "Standardize training and testing independent variables using `StandardScaler`\n",
    "\n",
    "To complete this process, do the following:\n",
    "\n",
    "- Create `StandardScaler` object and fit it with `x_train`\n",
    "- Transform `x_train` and assign transformed data to `x_train_ss`\n",
    "- Transform `x_test` and assign transformed data to `x_test_ss`\n",
    "\n",
    "After this problem, there are 2 new variables created, **x_train_ss** and __x_test_ss__\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1a2b609858d4cf7df309df03ede1a241",
     "grade": false,
     "grade_id": "p4-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9bf7db781a4c6fcc097b26dbd64588c8",
     "grade": true,
     "grade_id": "p4-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(x_train_ss[0][2], 1.17940189, msg=\"Training set is not standardized correctly\")\n",
    "assert_almost_equal(x_test_ss[0][0], -0.74018877, msg=\"Testing set is not standardized correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8dd24b73ddf1ee2edb3859c972b469bf",
     "grade": false,
     "grade_id": "cell-2e8febc890c84100",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "-----\n",
    "\n",
    "# Problem 5: Scale dataset\n",
    "\n",
    "This problem works on the variables **x_train** and __x_test__ created in problem 3.\n",
    "\n",
    "Scale training and testing independent variables using `MinMaxScaler`\n",
    "\n",
    "To complete this process, do the following:\n",
    "\n",
    "- Create `MinMaxScaler` object and fit it with `x_train`\n",
    "- Transform `x_train` and assign transformed data to `x_train_mm`\n",
    "- Transform `x_test` and assign transformed data to `x_test_mm`\n",
    "\n",
    "After this problem, there are 2 new variables created, **x_train_mm** and __x_test_mm__\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fbcead1f14bbd463eae4f5f9bf680292",
     "grade": false,
     "grade_id": "p5-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e0bd1a0e55a279d42bd48fa44b600df3",
     "grade": true,
     "grade_id": "p5-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(x_train_mm[0][0], 0.40673575129533684, msg=\"Training set is not scaled correctly\")\n",
    "assert_almost_equal(x_test_mm[0][0], 0.12435233160621761, msg=\"Testing set is not scaled correctly\")"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "data-analytics-accountancy-2",
   "graded_item_id": "GrQNK",
   "launcher_item_id": "m1_assignment"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

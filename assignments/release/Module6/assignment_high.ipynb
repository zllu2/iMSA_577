{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "737e62edcebb6f4354bf038d14179693",
     "grade": false,
     "grade_id": "cell-5aaea72c3751c7e2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Module 6 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Run the first code cell to import modules needed by this assignment before proceeding to problems.\n",
    "2. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "3. Each problem has an autograder cell below the answer cell. Run the autograder cell to check your answer. If there's anything wrong in your answer, the autograder cell will display error messages.\n",
    "4. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and Restart & Run all. If the notebook runs through the last code cell without error message, you've answered all problems correctly.\n",
    "5. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b254b51cc1c32d2c46e136c9c04dba92",
     "grade": false,
     "grade_id": "cell-aab57598618fe44d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Run Me First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "76c484feaa9128a5b35c7165fc3ca67a",
     "grade": false,
     "grade_id": "cell-88dd2a72c7ccd97d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance\n",
    "\n",
    "# We do this to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03cbdc4092342578d4c418474bee9550",
     "grade": false,
     "grade_id": "cell-c1ed02bea3557ccf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Prepare Yelp Review Data\n",
    "\n",
    "This assignment will use the Yelp review dataset. Before we attempt to build a model, we first prepare the data.\n",
    "\n",
    "The Yelp review dataset contains 1000 customer reviews of a group of restaurants. There are two columns in the dataset, column **stars** which is the star rating and column __text__ which is the review text. The dataset only contains 1-star and 5-star reviews. There are 500 1-star reviews and 500 5-star reviews.\n",
    "\n",
    "Please run the next code cell before proceeding to Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3d26404d26e304724936f1a7ba8c125b",
     "grade": false,
     "grade_id": "cell-dfcefdd4646fca8c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Load yelp review dataset\n",
    "df = pd.read_csv('data/yelp_reviews.csv')\n",
    "rating = df['stars']\n",
    "data = df['text']\n",
    "sample_review = data[0]\n",
    "print(f'Counts of Reviews by Star Rating:\\n{rating.value_counts()}\\n')\n",
    "print(f'Sample Review({rating[0]} stars):\\n{sample_review}')\n",
    "print('-'*80)\n",
    "print('\\nDataset Sample:')\n",
    "df.sample(2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e07a19079e8bd2468134d4a133bb978b",
     "grade": false,
     "grade_id": "cell-72a7a0ba38b0c4fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Problem 1: Prepare Data for Sentiment Analysis\n",
    "Create label and split text data set to training and testing set.\n",
    "\n",
    "For this problem you will use **data** and __rating__ created above.\n",
    "\n",
    "To solve this problem do the following:\n",
    "- Create **label** from __rating__, Set label to 1(positive) if rating is 5 stars and 0(negative) otherwise.(Hint: use lambda function: `label = rating.apply(lambda x: 1 if x==5 else 0)`\n",
    "- Split data and label to training and testing using `train_test_split`.\n",
    " - set test_size to 0.4\n",
    " - set random_state to 23\n",
    " - assign return values to **d_train, d_test, l_train, l_test**\n",
    "\n",
    "After this problem, there're four new variable, **d_train, d_test, l_train** and  __l_test__ defined.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3bee0da583bfcc56c5921c2fbab98d33",
     "grade": false,
     "grade_id": "p1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f416afa59c825472242858fc9f6e51a7",
     "grade": true,
     "grade_id": "p1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(d_train), 600, msg='training set size is not correct')\n",
    "assert_equal(len(d_test), 400, msg='testing set size is not correct')\n",
    "assert_equal(l_train.iloc[1], 1, msg='l_train is not correct')\n",
    "assert_equal(l_train.iloc[100], 1, msg='l_train is not correct')\n",
    "assert_equal(l_test.iloc[0], 0, msg='l_test is not correct')\n",
    "assert_equal(l_test.iloc[100], 1, msg='l_test is not correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec9d1ae2fcda9c9965bb2698d59f0d6d",
     "grade": false,
     "grade_id": "cell-30fe030e9e99b1f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 2: Train a LogisticRegression Model\n",
    "\n",
    "For this problem, use d_train, l_train, d_test and l_test created above.\n",
    "\n",
    "Your task for this problem is to build and train a `LogisticRegression` estimator to make predictions on the Yelp review dataset. \n",
    "\n",
    "To solve this problem do the following:\n",
    "- Create a `TfidfVectorizer` object **tf_cv**, set `stop_words` to 'english'.\n",
    "- Fit the `TfidfVectorizer` objec with d_train\n",
    "- Transform d_train and d_test with the `TfidfVectorizer` object to get **train_dtm** and __test_dtm__\n",
    "- Create a `LogisticRegression` estimator **lr_model**. Set `C` to `1E6`(1000000). Accept default values for all other hyperparameters.\n",
    "- Fit the `LogisticRegression` estimator using train_dtm and l_train.\n",
    "- Calcuate mean accuray score of **lr_model**\n",
    "    - Apply lr_model `predict` function on test_dtm created in problem 1 to get predicted label, assign it to variable **l_pred**.\n",
    "    - use `accuracy_score` function in `metrics` module on l_test and l_pred to calculate the mean accuracy score and assign score to **mas_score_lr**\n",
    "\n",
    "\n",
    "After this problem, there will be a trained LogisticRegression model **lr_model** defined, as well as two document term matrices, __train_dtm, test_dtm__, and **mas_score_lr**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "54d2be7f58eea1ad8bfd0d3fa2f5b68c",
     "grade": false,
     "grade_id": "p2-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "121448a530ca6cfd2e7518ff9425c6c5",
     "grade": true,
     "grade_id": "p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(lr_model), type(LogisticRegression()), msg=\"lr_model is not defined as a LogisticRegression model\")\n",
    "assert_equal(lr_model.get_params()['C'], 1E6, msg=\"lr_model is not created with C = 1E6\")\n",
    "assert_almost_equal(train_dtm[0, 132], 0.05808376842859404, msg=\"train_dtm is not correct\")\n",
    "assert_almost_equal(test_dtm[0, 157], 0.12459374859215833, msg=\"test_dtm is not correct\")\n",
    "assert_equal(mas_score_lr, 0.89, msg=\"Mean accuracy score is not correct\")\n",
    "print(f'Logistic Regression accuracy score: {mas_score_lr*100:4.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2cf2300f45a3e70b3cbfeac01b8d7786",
     "grade": false,
     "grade_id": "cell-5415042841073d6a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 3: Get Top 10 Words in Positive Reviews\n",
    "\n",
    "Get to 10 words in positive reviews.\n",
    "\n",
    "This problem will use **lr_model** and __tf_cv__ created in problem 2.\n",
    "\n",
    "To solve this problem do the following:\n",
    "- Use tf_cv `get_feature_names` function to get all tokens(words) from the TfidfVectorizer object. Convert the token list to numpy array and assign the numpy array to variable **all_words**.\n",
    "- Sort **lr_model** `coef_` attribute with `numpy argsort` function and get the last 10 items' index and assign to **top_words_index**\n",
    "- Get top 10 words using all_words and top_words_index and assign top 10 words list to **top10_positive_words**\n",
    "- Reverse top10_positive_words\n",
    "\n",
    "After this problem, there's a new variable **top10_positive_words** defined.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5441d36383ef903fd85f6f56f517c4da",
     "grade": false,
     "grade_id": "p3-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eb3555e2b59280aba85662ab9b39f588",
     "grade": true,
     "grade_id": "p3-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(top10_positive_words, ['best', 'love', 'amazing', 'great', 'delicious', 'awesome', 'good', 'little', 'highly', 'included'],\n",
    "             msg='Top 10 words in positive reviews are not correct')\n",
    "print(f\"Top 10 words in positive reviews:\\n {top10_positive_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4ace068b37e9af9a9934e6a30e95251b",
     "grade": false,
     "grade_id": "cell-04a5c3d6a5d2fa7a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 4: Get Top 10 Words in Negative Reviews\n",
    "\n",
    "Get to 10 words in negative reviews.\n",
    "\n",
    "This problem will use **lr_model, all_words, train_dtm, l_train** created above.\n",
    "\n",
    "To solve this problem do the following:\n",
    "- Reverse **l_train** values, change 0 to 1 and 1 to 0 and create another training label **l_train_2**\n",
    "- Fit the **lr_model** with __train_dtm__ and **l_train_2**\n",
    "- Get top 10 words from **lr_model**:\n",
    "    - Sort **lr_model** `coef_` attribute and get the last 10 items' index and assign to **top_words_index**\n",
    "    - Get top 10 words using all_words created in problem 3 and top_words_index and assign top 10 words list to **top10_negative_words**\n",
    "    - Reverse top10_negative_words\n",
    "\n",
    "After this problem, there's a new variable **top10_negative_words** defined.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "45e57b537091a521e7c28009006d738c",
     "grade": false,
     "grade_id": "p4-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "899aa08d78781e978488b95619c2dc7c",
     "grade": true,
     "grade_id": "p4-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(l_train[:5].tolist(), [0, 1, 1, 1, 1], \n",
    "             msg=\"You can't change l_train in this problem. Please fix the problem and run from problem 1 to reset l_train.\")\n",
    "assert_equal(top10_negative_words, ['bad', 'worst', 'horrible', 'poor', 'went', 'problem', 'dirty', 'tasted', 'ordered', 'company'],\n",
    "             msg='Top 10 words in negative reviews are not correct')\n",
    "print(f\"Top 10 words in negative reviews:\\n {top10_negative_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c914ae7e96fcfee55a13f0293aad770a",
     "grade": false,
     "grade_id": "cell-b14f916df8f7af19",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 5: Use Custom Stop Words\n",
    "\n",
    "Add two words in the top 10 words in negative reviews, \"went\" and \"company\" to English stop words and train a LogisticRegression model. The two words are rather neutral, we hope to get better classification result with this change.\n",
    "\n",
    "This problem will use **d_train, d_test, l_train, l_test** created in problem 1.\n",
    "\n",
    "To solve this problem do the following:\n",
    "- Get all English stop words from `stopwords` in `nltk.corpus` module, assign stop words list to variable **stop_words**.\n",
    "- Add two words \"went\" and \"company\" into stop_words\n",
    "- Create a `TfidfVectorizer` object **tf_cv_2**, set `stop_words` to stop_words created in step 2.\n",
    "- Fit the tf_cv_2 with d_train\n",
    "- Transform d_train and d_test with tf_cv_2 to get **train_dtm_2** and __test_dtm_2__\n",
    "- Create a `LogisticRegression` estimator **lr_model_2**. Set `C` to `1E6`(1000000). Accept default values for all other hyperparameters.\n",
    "- Fit lr_model_2 using train_dtm_2 and l_train.\n",
    "- Calcuate mean accuray score of **lr_model_2**\n",
    "    - Apply lr_model_2 `predict` function on test_dtm_2 to get predicted label, assign it to variable l_pred.\n",
    "    - use `accuracy_score` function in `metrics` module on l_test and l_pred to calculate the mean accuracy score and assign score to **mas_score_lr_2**\n",
    "\n",
    "\n",
    "After this problem, there will be a trained LogisticRegression model **lr_model_2** define, as well as two new document term matrices, __train_dtm_2, test_dtm_2__, and mean accuracy score **mas_score_lr_2**.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "527ee19d9157ecba4d04ef5a02c34a4e",
     "grade": false,
     "grade_id": "p5-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38caa3aecd84ef6fa53e37897a77c7f1",
     "grade": true,
     "grade_id": "p5-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(lr_model_2), type(LogisticRegression()), msg=\"lr_model is not defined as a LogisticRegression model\")\n",
    "assert_equal(lr_model_2.get_params()['C'], 1E6, msg=\"lr_model is not created with C = 1E6\")\n",
    "assert_almost_equal(train_dtm_2[0, 132], 0.056447087318836305, msg=\"train_dtm_2 is not correct\")\n",
    "assert_almost_equal(test_dtm_2[0, 157], 0.11448748543343225, msg=\"test_dtm_2 is not correct\")\n",
    "assert_equal(mas_score_lr_2, 0.8975, msg=\"Mean accuracy score is not correct\")\n",
    "print(f'Logistic Regression with custom stop words accuracy score: {mas_score_lr_2*100:5.2f}%')"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "data-analytics-accountancy-2",
   "graded_item_id": "GrQNK",
   "launcher_item_id": "m1_assignment"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

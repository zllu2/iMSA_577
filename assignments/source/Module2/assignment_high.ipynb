{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5aaea72c3751c7e2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Module 2 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Run the first code cell to import modules needed by this assignment before proceeding to problems.\n",
    "2. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "3. Each problem has an autograder cell below the answer cell. Run the autograder cell to check your answer. If there's anything wrong in your answer, the autograder cell will display error messages.\n",
    "4. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and Restart & Run all. If the notebook runs through the last code cell without an error message, you've answered all problems correctly.\n",
    "5. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aab57598618fe44d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Run Me First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88dd2a72c7ccd97d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5f7326f7846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massert_equal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massert_almost_equal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massert_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massert_is_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# We do this to ignore warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nose'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance\n",
    "\n",
    "# We do this to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04a5c3d6a5d2fa7a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "-----\n",
    "\n",
    "# Predicting Breast Cancer\n",
    "\n",
    "In this assignment, we will work with a breast cancer data set to make a classification model. Before we build a model, we first load the data into the assignment notebook, and then randomly sample several rows. Next we display the DataFrame information. The data is clean and all columns are numerical.\n",
    "\n",
    "Please run the next two Code cells before proceeding to Problem 1.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-067fcf4112b3f798",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Load breast cancer dataset\n",
    "df = pd.read_csv('data/breast-cancer-wisconsin.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-33750e46e3236618",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b14f916df8f7af19",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 1: Data Preprocessing\n",
    "\n",
    "For this problem you will use the DataFrame **df** defined above.\n",
    "\n",
    "To complete the task, do the following:\n",
    "1. Choose column 'class' as label and assign it to variable **label**. Note: since DataFrame has an attribute 'class', you can't refer to the 'class' column by using `df.class`. Use `df['class']` instead.\n",
    "2. Choose the following columns as training data and assign it to variable **data**:  \n",
    "'clump thickness', 'uniformity cell size', 'uniformity cell shape', 'marginal adhesion', 'epithelial cell size', 'bare nuclei', 'bland chromatin', 'normal nucleoli' and, 'mitoses'.   \n",
    "__data__ should be a DataFrame.\n",
    "3. Split the independent and dependent variables to training and testing set.\n",
    "    - Assign the training and testing data to variable d_train and d_test.\n",
    "    - Assign the training and testing label to variable l_train and l_test.\n",
    "    - The `test_size` argument in `train_test_split` should be set to 0.3.\n",
    "    - The `random_state` argument in `train_test_split` should be set to 23.\n",
    "\n",
    "After this problem, there are six new variables defined, **data, label, d_train, d_test, l_train** and __l_test__.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p1-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "label = df['class']\n",
    "data = df[['clump thickness', 'uniformity cell size', 'uniformity cell shape', 'marginal adhesion', 'epithelial cell size', 'bare nuclei', 'bland chromatin', 'normal nucleoli', 'mitoses']]\n",
    "d_train, d_test, l_train, l_test = train_test_split(data, label, test_size=0.3, random_state=23)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(data), pd.DataFrame, msg=\"data is not a DataFrame\")\n",
    "assert_equal(data.shape, (683, 9), msg=\"data is not correct\")\n",
    "assert_equal(len(l_test), 205, msg=\"Test set size is not correct.\")\n",
    "assert_equal(tuple(d_test.values[0]), (3, 2, 1, 1, 2, 2, 3, 1, 1),\n",
    "             msg='Test data is not correct. Make sure you set random_state=23 when splitting the dataset')\n",
    "#display first 2 training data\n",
    "d_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f0c9676010ba1122",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 2: Create and Train a Logistic Regression Model\n",
    "\n",
    "Your task for this problem is to build and use the scikit learn library's `LogisticRegression` estimator to make predictions on the breast cancer dataset.  \n",
    "\n",
    "To complete this task, you must explicitly:\n",
    "- Create a `LogisticRegression` estimator **lr_model** by using scikit learn. Accept default values for all arguments.\n",
    "- Fit the `LogisticRegression` estimator using d_train and l_train created in problem 1.\n",
    "\n",
    "After this problem, there will be a trained logistic regression model **lr_model**.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# Create and fit our logistic regression model to training data\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(d_train, l_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(lr_model), type(LogisticRegression()), msg=\"lr_model is not a LogisticRegression model\")\n",
    "assert_equal(lr_model.get_params()['C'], 1.0,\n",
    "            msg=\"lr_model is not created with all default argument values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0bd8ccf5e00ce321",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 3: Calculate Mean Accuracy Score\n",
    "\n",
    "For this problem, you will compute the mean accuracy score of the lr_model.  \n",
    "\n",
    "To complete this task, you must explicitly:\n",
    "\n",
    "- Apply lr_model `predict` function to d_test to get predicted label, assign it to variable **predicted**.\n",
    "- Compute the mean accuracy score using `accuracy_score` function in `metrics` module with true label **l_test** and predicted label __predicted__.\n",
    "- Assign the accuracy score to variable **mas_score**.\n",
    "\n",
    "After this problem, there will be a new variable **mas_score** defined.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p3-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "predicted = lr_model.predict(d_test)\n",
    "mas_score = metrics.accuracy_score(predicted, l_test)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(mas_score, 0.975609756097561, msg=\"Mean accuracy score is not correct\")\n",
    "print(f\"Logistic Regression prediction accuracy = {mas_score*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29cdc380fcceff0c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 4: Create and Train a Decision Tree Classifier\n",
    "\n",
    "Your task for this problem is to build and use the scikit learn library's `DecisionTreeClassifier` estimator to make predictions on the breast cancer dataset. \n",
    "\n",
    "To complete this function, you must explicitly:\n",
    "- Create a `DecisionTreeClassifier` estimator **dtc_model** by using scikit learn. Set **random_state** to 23 and accept default values for all other hyperparameters.\n",
    "- Fit the `DecisionTreeClassifier` estimator using d_train and l_train created in problem 1.\n",
    "\n",
    "After this problem, there will be a trained decision tree classification model **dtc_model**.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p4-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# Create and fit our logistic regression model to training data\n",
    "dtc_model = DecisionTreeClassifier(random_state=23)\n",
    "dtc_model.fit(d_train, l_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p4-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(dtc_model), type(DecisionTreeClassifier()), msg=\"dtc_model is not a DecisionTreeClassifier\")\n",
    "assert_equal(dtc_model.get_params()['random_state'], 23,\n",
    "            msg=\"dtc_model is not created with random_state 23\")\n",
    "assert_equal(dtc_model.get_params()['criterion'], 'gini',\n",
    "            msg=\"dtc_model is not created with all default argument values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a98dc2ad783edc1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 5: Calculate Mean Accuracy Score\n",
    "\n",
    "For this problem, you will compute the mean accuracy score of the dtc_model.\n",
    "\n",
    "To complete this function, you must explicitly:\n",
    "\n",
    "- Apply dtc_model `predict` function to d_test to get predicted label, assign it to variable **predicted_dtc**.\n",
    "- Compute the mean accuracy score using `accuracy_score` function in `metrics` module with true label **l_test** and predicted label __predicted_dtc__.\n",
    "- Assign the accuracy score to variable **mas_score_dtc**.\n",
    "\n",
    "After this problem, there will be a new variable **mas_score_dtc** defined.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p5-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "predicted_dtc = dtc_model.predict(d_test)\n",
    "mas_score_dtc = metrics.accuracy_score(predicted_dtc, l_test)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p5-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(mas_score_dtc, 0.9609756097560975, msg=\"Mean accuracy score is not correct\")\n",
    "print(f\"Decision Tree prediction accuracy = {mas_score_dtc*100:4.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "coursera": {
   "course_slug": "data-analytics-accountancy-2",
   "graded_item_id": "GrQNK",
   "launcher_item_id": "m1_assignment"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
